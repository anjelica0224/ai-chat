{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adce7215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:42:54.816570Z",
     "iopub.status.busy": "2025-11-29T12:42:54.816300Z",
     "iopub.status.idle": "2025-11-29T14:45:14.193007Z",
     "shell.execute_reply": "2025-11-29T14:45:14.191639Z"
    },
    "papermill": {
     "duration": 7339.382316,
     "end_time": "2025-11-29T14:45:14.194845",
     "exception": false,
     "start_time": "2025-11-29T12:42:54.812529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB_SIZE = 41 (BLANK + 39 phonemes + silence)\n",
      "Phoneme set: ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G', 'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'T', 'TH', 'UH', 'UW', 'V', 'W', 'Y', 'Z', 'ZH', ' | ']\n",
      "============================================================\n",
      "LOADING FULL DATASET...\n",
      "============================================================\n",
      "\n",
      "Found 45 training files\n",
      "Found 41 validation files\n",
      "\n",
      "Loading training trials...\n",
      "  data_train.hdf5: 288 trials\n",
      "  data_train.hdf5: 348 trials\n",
      "  data_train.hdf5: 197 trials\n",
      "  data_train.hdf5: 278 trials\n",
      "  data_train.hdf5: 88 trials\n",
      "  data_train.hdf5: 150 trials\n",
      "  data_train.hdf5: 297 trials\n",
      "  data_train.hdf5: 322 trials\n",
      "  data_train.hdf5: 245 trials\n",
      "  data_train.hdf5: 153 trials\n",
      "  data_train.hdf5: 218 trials\n",
      "  data_train.hdf5: 174 trials\n",
      "  data_train.hdf5: 284 trials\n",
      "  data_train.hdf5: 155 trials\n",
      "  data_train.hdf5: 239 trials\n",
      "  data_train.hdf5: 98 trials\n",
      "  data_train.hdf5: 134 trials\n",
      "  data_train.hdf5: 149 trials\n",
      "  data_train.hdf5: 80 trials\n",
      "  data_train.hdf5: 100 trials\n",
      "  data_train.hdf5: 60 trials\n",
      "  data_train.hdf5: 198 trials\n",
      "  data_train.hdf5: 228 trials\n",
      "  data_train.hdf5: 198 trials\n",
      "  data_train.hdf5: 131 trials\n",
      "  data_train.hdf5: 135 trials\n",
      "  data_train.hdf5: 198 trials\n",
      "  data_train.hdf5: 193 trials\n",
      "  data_train.hdf5: 219 trials\n",
      "  data_train.hdf5: 163 trials\n",
      "  data_train.hdf5: 239 trials\n",
      "  data_train.hdf5: 246 trials\n",
      "  data_train.hdf5: 364 trials\n",
      "  data_train.hdf5: 150 trials\n",
      "  data_train.hdf5: 110 trials\n",
      "  data_train.hdf5: 90 trials\n",
      "  data_train.hdf5: 169 trials\n",
      "  data_train.hdf5: 160 trials\n",
      "  data_train.hdf5: 161 trials\n",
      "  data_train.hdf5: 106 trials\n",
      "  data_train.hdf5: 163 trials\n",
      "  data_train.hdf5: 59 trials\n",
      "  data_train.hdf5: 101 trials\n",
      "  data_train.hdf5: 165 trials\n",
      "  data_train.hdf5: 69 trials\n",
      "\n",
      "Total trials found: 8072\n",
      "\n",
      "Loading validation trials...\n",
      "  data_val.hdf5: 35 trials\n",
      "  data_val.hdf5: 49 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 49 trials\n",
      "  data_val.hdf5: 34 trials\n",
      "  data_val.hdf5: 35 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 44 trials\n",
      "  data_val.hdf5: 36 trials\n",
      "  data_val.hdf5: 17 trials\n",
      "  data_val.hdf5: 44 trials\n",
      "  data_val.hdf5: 44 trials\n",
      "  data_val.hdf5: 9 trials\n",
      "  data_val.hdf5: 33 trials\n",
      "  data_val.hdf5: 50 trials\n",
      "  data_val.hdf5: 15 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 20 trials\n",
      "  data_val.hdf5: 44 trials\n",
      "  data_val.hdf5: 34 trials\n",
      "  data_val.hdf5: 50 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 30 trials\n",
      "  data_val.hdf5: 50 trials\n",
      "  data_val.hdf5: 23 trials\n",
      "  data_val.hdf5: 24 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 46 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 23 trials\n",
      "  data_val.hdf5: 47 trials\n",
      "  data_val.hdf5: 24 trials\n",
      "  data_val.hdf5: 24 trials\n",
      "  data_val.hdf5: 30 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "\n",
      "Total trials found: 1426\n",
      "Dataset initialized with 8072 trials\n",
      "Dataset initialized with 1426 trials\n",
      "\n",
      "DataLoader created:\n",
      "  Train batches: 2018\n",
      "  Val batches: 713\n",
      "\n",
      "Model parameters: 3,301,417\n",
      "\n",
      "============================================================\n",
      "STARTING TRAINING ON FULL DATASET\n",
      "============================================================\n",
      "  Batch 100/2018 | Loss: 3.7575\n",
      "  Batch 200/2018 | Loss: 3.2853\n",
      "  Batch 300/2018 | Loss: 3.2761\n",
      "  Batch 400/2018 | Loss: 3.1945\n",
      "  Batch 500/2018 | Loss: 3.1540\n",
      "  Batch 600/2018 | Loss: 3.3175\n",
      "  Batch 700/2018 | Loss: 3.2402\n",
      "  Batch 800/2018 | Loss: 3.1718\n",
      "  Batch 900/2018 | Loss: 3.3185\n",
      "  Batch 1000/2018 | Loss: 3.1590\n",
      "  Batch 1100/2018 | Loss: 3.0929\n",
      "  Batch 1200/2018 | Loss: 2.8712\n",
      "  Batch 1300/2018 | Loss: 3.0084\n",
      "  Batch 1400/2018 | Loss: 2.8586\n",
      "  Batch 1500/2018 | Loss: 2.8106\n",
      "  Batch 1600/2018 | Loss: 2.9203\n",
      "  Batch 1700/2018 | Loss: 2.8300\n",
      "  Batch 1800/2018 | Loss: 2.7697\n",
      "  Batch 1900/2018 | Loss: 2.5159\n",
      "  Batch 2000/2018 | Loss: 2.7190\n",
      "\n",
      "EPOCH 1/30 | Avg Loss: 5.0803\n",
      "  Batch 100/2018 | Loss: 2.5934\n",
      "  Batch 200/2018 | Loss: 2.5794\n",
      "  Batch 300/2018 | Loss: 2.3826\n",
      "  Batch 400/2018 | Loss: 2.6816\n",
      "  Batch 500/2018 | Loss: 2.4522\n",
      "  Batch 600/2018 | Loss: 2.6764\n",
      "  Batch 700/2018 | Loss: 2.4864\n",
      "  Batch 800/2018 | Loss: 2.5969\n",
      "  Batch 900/2018 | Loss: 2.4535\n",
      "  Batch 1000/2018 | Loss: 2.4022\n",
      "  Batch 1100/2018 | Loss: 2.2883\n",
      "  Batch 1200/2018 | Loss: 2.7738\n",
      "  Batch 1300/2018 | Loss: 2.2725\n",
      "  Batch 1400/2018 | Loss: 2.4951\n",
      "  Batch 1500/2018 | Loss: 2.3281\n",
      "  Batch 1600/2018 | Loss: 2.3922\n",
      "  Batch 1700/2018 | Loss: 2.2741\n",
      "  Batch 1800/2018 | Loss: 2.0740\n",
      "  Batch 1900/2018 | Loss: 2.1346\n",
      "  Batch 2000/2018 | Loss: 2.1347\n",
      "\n",
      "EPOCH 2/30 | Avg Loss: 2.4379\n",
      "  Batch 100/2018 | Loss: 1.9181\n",
      "  Batch 200/2018 | Loss: 2.2013\n",
      "  Batch 300/2018 | Loss: 2.2567\n",
      "  Batch 400/2018 | Loss: 2.3315\n",
      "  Batch 500/2018 | Loss: 2.1134\n",
      "  Batch 600/2018 | Loss: 1.7808\n",
      "  Batch 700/2018 | Loss: 2.0157\n",
      "  Batch 800/2018 | Loss: 1.9181\n",
      "  Batch 900/2018 | Loss: 1.9456\n",
      "  Batch 1000/2018 | Loss: 2.2934\n",
      "  Batch 1100/2018 | Loss: 2.0325\n",
      "  Batch 1200/2018 | Loss: 2.1641\n",
      "  Batch 1300/2018 | Loss: 2.2712\n",
      "  Batch 1400/2018 | Loss: 1.7809\n",
      "  Batch 1500/2018 | Loss: 2.1910\n",
      "  Batch 1600/2018 | Loss: 1.5095\n",
      "  Batch 1700/2018 | Loss: 1.5475\n",
      "  Batch 1800/2018 | Loss: 1.8584\n",
      "  Batch 1900/2018 | Loss: 2.0023\n",
      "  Batch 2000/2018 | Loss: 1.9136\n",
      "\n",
      "EPOCH 3/30 | Avg Loss: 2.0012\n",
      "\n",
      "Running full validation...\n",
      "Starting validation...\n",
      "  Validated 50/713 batches\n",
      "  Validated 100/713 batches\n",
      "  Validated 150/713 batches\n",
      "  Validated 200/713 batches\n",
      "  Validated 250/713 batches\n",
      "  Validated 300/713 batches\n",
      "  Validated 350/713 batches\n",
      "  Validated 400/713 batches\n",
      "  Validated 450/713 batches\n",
      "  Validated 500/713 batches\n",
      "  Validated 550/713 batches\n",
      "  Validated 600/713 batches\n",
      "  Validated 650/713 batches\n",
      "  Validated 700/713 batches\n",
      "\n",
      "Validation Results:\n",
      "  Total edit distance: 32375\n",
      "  Total sequence length: 41392\n",
      "  PER: 78.22%\n",
      "✓ NEW BEST MODEL SAVED!\n",
      "\n",
      "Sample predictions (phonemes):\n",
      "Sample 1:\n",
      "  Truth: Y UW  |  K AE N  |  S IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE Z  |  W EH L  | \n",
      "  Pred:   |   |   |   |   |   |   |   |   |   | \n",
      "Sample 2:\n",
      "  Truth: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AA S T  |  D AW N  | \n",
      "  Pred:   |   |   |   |   |   |   | \n",
      "Sample 3:\n",
      "  Truth: N AA T  |  T UW  |  K AA N T R AH V ER SH AH L  | \n",
      "  Pred:   |   |   |   |   |   | \n",
      "------------------------------------------------------------\n",
      "  Batch 100/2018 | Loss: 1.8457\n",
      "  Batch 200/2018 | Loss: 1.7902\n",
      "  Batch 300/2018 | Loss: 1.8059\n",
      "  Batch 400/2018 | Loss: 1.9589\n",
      "  Batch 500/2018 | Loss: 1.8067\n",
      "  Batch 600/2018 | Loss: 1.3850\n",
      "  Batch 700/2018 | Loss: 1.7768\n",
      "  Batch 800/2018 | Loss: 1.5618\n",
      "  Batch 900/2018 | Loss: 1.5939\n",
      "  Batch 1000/2018 | Loss: 1.7434\n",
      "  Batch 1100/2018 | Loss: 1.7719\n",
      "  Batch 1200/2018 | Loss: 1.6998\n",
      "  Batch 1300/2018 | Loss: 1.9502\n",
      "  Batch 1400/2018 | Loss: 1.3748\n",
      "  Batch 1500/2018 | Loss: 1.7804\n",
      "  Batch 1600/2018 | Loss: 2.0403\n",
      "  Batch 1700/2018 | Loss: 1.2308\n",
      "  Batch 1800/2018 | Loss: 1.6509\n",
      "  Batch 1900/2018 | Loss: 1.7079\n",
      "  Batch 2000/2018 | Loss: 2.0128\n",
      "\n",
      "EPOCH 4/30 | Avg Loss: 1.6954\n",
      "  Batch 100/2018 | Loss: 1.3343\n",
      "  Batch 200/2018 | Loss: 1.4086\n",
      "  Batch 300/2018 | Loss: 1.4579\n",
      "  Batch 400/2018 | Loss: 1.4666\n",
      "  Batch 500/2018 | Loss: 1.5279\n",
      "  Batch 600/2018 | Loss: 1.7251\n",
      "  Batch 700/2018 | Loss: 1.5089\n",
      "  Batch 800/2018 | Loss: 1.3491\n",
      "  Batch 900/2018 | Loss: 1.0224\n",
      "  Batch 1000/2018 | Loss: 1.6479\n",
      "  Batch 1100/2018 | Loss: 1.3524\n",
      "  Batch 1200/2018 | Loss: 1.6925\n",
      "  Batch 1300/2018 | Loss: 1.3480\n",
      "  Batch 1400/2018 | Loss: 1.4060\n",
      "  Batch 1500/2018 | Loss: 2.1323\n",
      "  Batch 1600/2018 | Loss: 1.0384\n",
      "  Batch 1700/2018 | Loss: 1.4332\n",
      "  Batch 1800/2018 | Loss: 1.3980\n",
      "  Batch 1900/2018 | Loss: 1.5343\n",
      "  Batch 2000/2018 | Loss: 1.2036\n",
      "\n",
      "EPOCH 5/30 | Avg Loss: 1.4704\n",
      "  Batch 100/2018 | Loss: 1.3168\n",
      "  Batch 200/2018 | Loss: 1.7097\n",
      "  Batch 300/2018 | Loss: 1.3506\n",
      "  Batch 400/2018 | Loss: 1.0288\n",
      "  Batch 500/2018 | Loss: 1.2878\n",
      "  Batch 600/2018 | Loss: 0.8194\n",
      "  Batch 700/2018 | Loss: 1.1274\n",
      "  Batch 800/2018 | Loss: 1.6303\n",
      "  Batch 900/2018 | Loss: 0.7786\n",
      "  Batch 1000/2018 | Loss: 1.1683\n",
      "  Batch 1100/2018 | Loss: 1.7170\n",
      "  Batch 1200/2018 | Loss: 1.7891\n",
      "  Batch 1300/2018 | Loss: 1.3019\n",
      "  Batch 1400/2018 | Loss: 1.4183\n",
      "  Batch 1500/2018 | Loss: 1.1306\n",
      "  Batch 1600/2018 | Loss: 1.0380\n",
      "  Batch 1700/2018 | Loss: 1.0249\n",
      "  Batch 1800/2018 | Loss: 1.1645\n",
      "  Batch 1900/2018 | Loss: 1.0485\n",
      "  Batch 2000/2018 | Loss: 1.3629\n",
      "\n",
      "EPOCH 6/30 | Avg Loss: 1.2252\n",
      "\n",
      "Running full validation...\n",
      "Starting validation...\n",
      "  Validated 50/713 batches\n",
      "  Validated 100/713 batches\n",
      "  Validated 150/713 batches\n",
      "  Validated 200/713 batches\n",
      "  Validated 250/713 batches\n",
      "  Validated 300/713 batches\n",
      "  Validated 350/713 batches\n",
      "  Validated 400/713 batches\n",
      "  Validated 450/713 batches\n",
      "  Validated 500/713 batches\n",
      "  Validated 550/713 batches\n",
      "  Validated 600/713 batches\n",
      "  Validated 650/713 batches\n",
      "  Validated 700/713 batches\n",
      "\n",
      "Validation Results:\n",
      "  Total edit distance: 19888\n",
      "  Total sequence length: 41392\n",
      "  PER: 48.05%\n",
      "✓ NEW BEST MODEL SAVED!\n",
      "\n",
      "Sample predictions (phonemes):\n",
      "Sample 1:\n",
      "  Truth: Y UW  |  K AE N  |  S IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE Z  |  W EH L  | \n",
      "  Pred:  Y UW  |  UH D  |  IY  |  DH AH  |  G UH OW  |  AH T  |  DH IH  |  R  |   |  W  | \n",
      "Sample 2:\n",
      "  Truth: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AA S T  |  D AW N  | \n",
      "  Pred:  AW  |  AH Z  |  IH  |  IY UW  |  DH AH  |  L W S T  |   | \n",
      "Sample 3:\n",
      "  Truth: N AA T  |  T UW  |  K AA N T R AH V ER SH AH L  | \n",
      "  Pred:  N AA T  |  UW  |   | \n",
      "------------------------------------------------------------\n",
      "  Batch 100/2018 | Loss: 0.9215\n",
      "  Batch 200/2018 | Loss: 0.6824\n",
      "  Batch 300/2018 | Loss: 1.3225\n",
      "  Batch 400/2018 | Loss: 1.3872\n",
      "  Batch 500/2018 | Loss: 0.8080\n",
      "  Batch 600/2018 | Loss: 1.0414\n",
      "  Batch 700/2018 | Loss: 1.2906\n",
      "  Batch 800/2018 | Loss: 0.7471\n",
      "  Batch 900/2018 | Loss: 0.9705\n",
      "  Batch 1000/2018 | Loss: 0.8851\n",
      "  Batch 1100/2018 | Loss: 1.0919\n",
      "  Batch 1200/2018 | Loss: 1.0525\n",
      "  Batch 1300/2018 | Loss: 1.1948\n",
      "  Batch 1400/2018 | Loss: 0.9705\n",
      "  Batch 1500/2018 | Loss: 0.6089\n",
      "  Batch 1600/2018 | Loss: 1.0476\n",
      "  Batch 1700/2018 | Loss: 0.8938\n",
      "  Batch 1800/2018 | Loss: 1.0097\n",
      "  Batch 1900/2018 | Loss: 1.9266\n",
      "  Batch 2000/2018 | Loss: 1.0201\n",
      "\n",
      "EPOCH 7/30 | Avg Loss: 1.0458\n",
      "  Batch 100/2018 | Loss: 0.6265\n",
      "  Batch 200/2018 | Loss: 0.7162\n",
      "  Batch 300/2018 | Loss: 1.3888\n",
      "  Batch 400/2018 | Loss: 0.9406\n",
      "  Batch 500/2018 | Loss: 1.1726\n",
      "  Batch 600/2018 | Loss: 0.8425\n",
      "  Batch 700/2018 | Loss: 0.6299\n",
      "  Batch 800/2018 | Loss: 0.8280\n",
      "  Batch 900/2018 | Loss: 1.6396\n",
      "  Batch 1000/2018 | Loss: 0.5931\n",
      "  Batch 1100/2018 | Loss: 0.7785\n",
      "  Batch 1200/2018 | Loss: 1.1594\n",
      "  Batch 1300/2018 | Loss: 1.0546\n",
      "  Batch 1400/2018 | Loss: 0.7392\n",
      "  Batch 1500/2018 | Loss: 1.0486\n",
      "  Batch 1600/2018 | Loss: 0.6907\n",
      "  Batch 1700/2018 | Loss: 1.0689\n",
      "  Batch 1800/2018 | Loss: 1.2155\n",
      "  Batch 1900/2018 | Loss: 0.7045\n",
      "  Batch 2000/2018 | Loss: 0.6990\n",
      "\n",
      "EPOCH 8/30 | Avg Loss: 0.9247\n",
      "  Batch 100/2018 | Loss: 0.3569\n",
      "  Batch 200/2018 | Loss: 1.1866\n",
      "  Batch 300/2018 | Loss: 0.3989\n",
      "  Batch 400/2018 | Loss: 0.7736\n",
      "  Batch 500/2018 | Loss: 0.5788\n",
      "  Batch 600/2018 | Loss: 0.5466\n",
      "  Batch 700/2018 | Loss: 1.0881\n",
      "  Batch 800/2018 | Loss: 0.7737\n",
      "  Batch 900/2018 | Loss: 0.7456\n",
      "  Batch 1000/2018 | Loss: 0.7843\n",
      "  Batch 1100/2018 | Loss: 1.0540\n",
      "  Batch 1200/2018 | Loss: 0.7540\n",
      "  Batch 1300/2018 | Loss: 0.9090\n",
      "  Batch 1400/2018 | Loss: 0.9070\n",
      "  Batch 1500/2018 | Loss: 0.7384\n",
      "  Batch 1600/2018 | Loss: 0.6823\n",
      "  Batch 1700/2018 | Loss: 1.3430\n",
      "  Batch 1800/2018 | Loss: 0.8717\n",
      "  Batch 1900/2018 | Loss: 0.5698\n",
      "  Batch 2000/2018 | Loss: 1.2870\n",
      "\n",
      "EPOCH 9/30 | Avg Loss: 0.8286\n",
      "\n",
      "Running full validation...\n",
      "Starting validation...\n",
      "  Validated 50/713 batches\n",
      "  Validated 100/713 batches\n",
      "  Validated 150/713 batches\n",
      "  Validated 200/713 batches\n",
      "  Validated 250/713 batches\n",
      "  Validated 300/713 batches\n",
      "  Validated 350/713 batches\n",
      "  Validated 400/713 batches\n",
      "  Validated 450/713 batches\n",
      "  Validated 500/713 batches\n",
      "  Validated 550/713 batches\n",
      "  Validated 600/713 batches\n",
      "  Validated 650/713 batches\n",
      "  Validated 700/713 batches\n",
      "\n",
      "Validation Results:\n",
      "  Total edit distance: 14384\n",
      "  Total sequence length: 41392\n",
      "  PER: 34.75%\n",
      "✓ NEW BEST MODEL SAVED!\n",
      "\n",
      "Sample predictions (phonemes):\n",
      "Sample 1:\n",
      "  Truth: Y UW  |  K AE N  |  S IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE Z  |  W EH L  | \n",
      "  Pred:  Y UW  |  K AE D  |  SH IY  |  DH AH  |  K OW D  |  AE T  |  DH IH  |  P OY N T  |  AE Z  |  W AY  | \n",
      "Sample 2:\n",
      "  Truth: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AA S T  |  D AW N  | \n",
      "  Pred:  HH AW  |  D AH S  |  IH T  |  G IY P  |  DH AH  |  K W AH T  |  D  |   | \n",
      "Sample 3:\n",
      "  Truth: N AA T  |  T UW  |  K AA N T R AH V ER SH AH L  | \n",
      "  Pred:  N AA T  |  T UW  |  N T AE SH L  | \n",
      "------------------------------------------------------------\n",
      "  Batch 100/2018 | Loss: 0.6151\n",
      "  Batch 200/2018 | Loss: 0.8196\n",
      "  Batch 300/2018 | Loss: 0.4241\n",
      "  Batch 400/2018 | Loss: 0.9513\n",
      "  Batch 500/2018 | Loss: 0.7142\n",
      "  Batch 600/2018 | Loss: 0.7728\n",
      "  Batch 700/2018 | Loss: 1.0643\n",
      "  Batch 800/2018 | Loss: 0.8110\n",
      "  Batch 900/2018 | Loss: 0.6326\n",
      "  Batch 1000/2018 | Loss: 0.9574\n",
      "  Batch 1100/2018 | Loss: 1.5020\n",
      "  Batch 1200/2018 | Loss: 0.8943\n",
      "  Batch 1300/2018 | Loss: 0.7626\n",
      "  Batch 1400/2018 | Loss: 0.6743\n",
      "  Batch 1500/2018 | Loss: 0.5456\n",
      "  Batch 1600/2018 | Loss: 0.7473\n",
      "  Batch 1700/2018 | Loss: 0.7920\n",
      "  Batch 1800/2018 | Loss: 0.7031\n",
      "  Batch 1900/2018 | Loss: 0.9527\n",
      "  Batch 2000/2018 | Loss: 0.5384\n",
      "\n",
      "EPOCH 10/30 | Avg Loss: 0.7486\n",
      "  Batch 100/2018 | Loss: 0.7680\n",
      "  Batch 200/2018 | Loss: 0.6791\n",
      "  Batch 300/2018 | Loss: 0.6523\n",
      "  Batch 400/2018 | Loss: 1.1951\n",
      "  Batch 500/2018 | Loss: 0.7394\n",
      "  Batch 600/2018 | Loss: 0.1525\n",
      "  Batch 700/2018 | Loss: 0.7493\n",
      "  Batch 800/2018 | Loss: 0.6347\n",
      "  Batch 900/2018 | Loss: 1.0535\n",
      "  Batch 1000/2018 | Loss: 0.3736\n",
      "  Batch 1100/2018 | Loss: 0.6102\n",
      "  Batch 1200/2018 | Loss: 0.5448\n",
      "  Batch 1300/2018 | Loss: 0.3922\n",
      "  Batch 1400/2018 | Loss: 0.8407\n",
      "  Batch 1500/2018 | Loss: 1.1724\n",
      "  Batch 1600/2018 | Loss: 0.9594\n",
      "  Batch 1700/2018 | Loss: 1.1566\n",
      "  Batch 1800/2018 | Loss: 0.6399\n",
      "  Batch 1900/2018 | Loss: 0.3766\n",
      "  Batch 2000/2018 | Loss: 0.6997\n",
      "\n",
      "EPOCH 11/30 | Avg Loss: 0.6861\n",
      "  Batch 100/2018 | Loss: 0.5929\n",
      "  Batch 200/2018 | Loss: 1.3747\n",
      "  Batch 300/2018 | Loss: 0.7861\n",
      "  Batch 400/2018 | Loss: 0.3383\n",
      "  Batch 500/2018 | Loss: 1.1416\n",
      "  Batch 600/2018 | Loss: 0.5529\n",
      "  Batch 700/2018 | Loss: 0.4326\n",
      "  Batch 800/2018 | Loss: 0.5144\n",
      "  Batch 900/2018 | Loss: 0.4059\n",
      "  Batch 1000/2018 | Loss: 1.5318\n",
      "  Batch 1100/2018 | Loss: 0.5758\n",
      "  Batch 1200/2018 | Loss: 0.5398\n",
      "  Batch 1300/2018 | Loss: 0.4939\n",
      "  Batch 1400/2018 | Loss: 0.7443\n",
      "  Batch 1500/2018 | Loss: 0.8636\n",
      "  Batch 1600/2018 | Loss: 0.6497\n",
      "  Batch 1700/2018 | Loss: 0.7618\n",
      "  Batch 1800/2018 | Loss: 0.4323\n",
      "  Batch 1900/2018 | Loss: 0.6322\n",
      "  Batch 2000/2018 | Loss: 0.7550\n",
      "\n",
      "EPOCH 12/30 | Avg Loss: 0.6230\n",
      "\n",
      "Running full validation...\n",
      "Starting validation...\n",
      "  Validated 50/713 batches\n",
      "  Validated 100/713 batches\n",
      "  Validated 150/713 batches\n",
      "  Validated 200/713 batches\n",
      "  Validated 250/713 batches\n",
      "  Validated 300/713 batches\n",
      "  Validated 350/713 batches\n",
      "  Validated 400/713 batches\n",
      "  Validated 450/713 batches\n",
      "  Validated 500/713 batches\n",
      "  Validated 550/713 batches\n",
      "  Validated 600/713 batches\n",
      "  Validated 650/713 batches\n",
      "  Validated 700/713 batches\n",
      "\n",
      "Validation Results:\n",
      "  Total edit distance: 12417\n",
      "  Total sequence length: 41392\n",
      "  PER: 30.00%\n",
      "✓ NEW BEST MODEL SAVED!\n",
      "\n",
      "Sample predictions (phonemes):\n",
      "Sample 1:\n",
      "  Truth: Y UW  |  K AE N  |  S IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE Z  |  W EH L  | \n",
      "  Pred:  Y UW  |  AE N  |  IY  |  DH AH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AH S Z  |  W EH  | \n",
      "Sample 2:\n",
      "  Truth: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AA S T  |  D AW N  | \n",
      "  Pred:  HH AW  |  JH AH Z  |  IH T  |  K IY P  |  DH  |  W AH S T  |  IH D  | \n",
      "Sample 3:\n",
      "  Truth: N AA T  |  T UW  |  K AA N T R AH V ER SH AH L  | \n",
      "  Pred:  N AA T  |  D UW  |  K AH CH AE ER AH UW L AH  | \n",
      "------------------------------------------------------------\n",
      "  Batch 100/2018 | Loss: 0.5481\n",
      "  Batch 200/2018 | Loss: 0.5277\n",
      "  Batch 300/2018 | Loss: 0.3453\n",
      "  Batch 400/2018 | Loss: 0.4048\n",
      "  Batch 500/2018 | Loss: 0.9035\n",
      "  Batch 600/2018 | Loss: 0.7254\n",
      "  Batch 700/2018 | Loss: 0.8554\n",
      "  Batch 800/2018 | Loss: 0.4580\n",
      "  Batch 900/2018 | Loss: 0.6395\n",
      "  Batch 1000/2018 | Loss: 0.7813\n",
      "  Batch 1100/2018 | Loss: 0.5147\n",
      "  Batch 1200/2018 | Loss: 0.8437\n",
      "  Batch 1300/2018 | Loss: 0.6451\n",
      "  Batch 1400/2018 | Loss: 0.4447\n",
      "  Batch 1500/2018 | Loss: 0.4246\n",
      "  Batch 1600/2018 | Loss: 0.5436\n",
      "  Batch 1700/2018 | Loss: 0.3910\n",
      "  Batch 1800/2018 | Loss: 0.4018\n",
      "  Batch 1900/2018 | Loss: 0.3661\n",
      "  Batch 2000/2018 | Loss: 0.2518\n",
      "\n",
      "EPOCH 13/30 | Avg Loss: 0.5657\n",
      "  Batch 100/2018 | Loss: 0.5365\n",
      "  Batch 200/2018 | Loss: 0.2842\n",
      "  Batch 300/2018 | Loss: 0.6875\n",
      "  Batch 400/2018 | Loss: 0.7878\n",
      "  Batch 500/2018 | Loss: 0.5331\n",
      "  Batch 600/2018 | Loss: 0.7495\n",
      "  Batch 700/2018 | Loss: 0.4584\n",
      "  Batch 800/2018 | Loss: 0.7184\n",
      "  Batch 900/2018 | Loss: 0.6501\n",
      "  Batch 1000/2018 | Loss: 0.4738\n",
      "  Batch 1100/2018 | Loss: 0.5593\n",
      "  Batch 1200/2018 | Loss: 0.6328\n",
      "  Batch 1300/2018 | Loss: 0.5175\n",
      "  Batch 1400/2018 | Loss: 0.3243\n",
      "  Batch 1500/2018 | Loss: 0.2926\n",
      "  Batch 1600/2018 | Loss: 0.4782\n",
      "  Batch 1700/2018 | Loss: 0.3479\n",
      "  Batch 1800/2018 | Loss: 0.3182\n",
      "  Batch 1900/2018 | Loss: 0.3013\n",
      "  Batch 2000/2018 | Loss: 0.2857\n",
      "\n",
      "EPOCH 14/30 | Avg Loss: 0.5133\n",
      "  Batch 100/2018 | Loss: 0.4366\n",
      "  Batch 200/2018 | Loss: 0.6561\n",
      "  Batch 300/2018 | Loss: 0.6230\n",
      "  Batch 400/2018 | Loss: 0.5743\n",
      "  Batch 500/2018 | Loss: 0.4085\n",
      "  Batch 600/2018 | Loss: 0.4121\n",
      "  Batch 700/2018 | Loss: 0.4322\n",
      "  Batch 800/2018 | Loss: 0.1853\n",
      "  Batch 900/2018 | Loss: 0.9151\n",
      "  Batch 1000/2018 | Loss: 0.3039\n",
      "  Batch 1100/2018 | Loss: 0.2701\n",
      "  Batch 1200/2018 | Loss: 0.2908\n",
      "  Batch 1300/2018 | Loss: 0.6151\n",
      "  Batch 1400/2018 | Loss: 0.5134\n",
      "  Batch 1500/2018 | Loss: 0.6871\n",
      "  Batch 1600/2018 | Loss: 0.4430\n",
      "  Batch 1700/2018 | Loss: 0.5792\n",
      "  Batch 1800/2018 | Loss: 0.5775\n",
      "  Batch 1900/2018 | Loss: 0.3805\n",
      "  Batch 2000/2018 | Loss: 0.4290\n",
      "\n",
      "EPOCH 15/30 | Avg Loss: 0.4651\n",
      "\n",
      "Running full validation...\n",
      "Starting validation...\n",
      "  Validated 50/713 batches\n",
      "  Validated 100/713 batches\n",
      "  Validated 150/713 batches\n",
      "  Validated 200/713 batches\n",
      "  Validated 250/713 batches\n",
      "  Validated 300/713 batches\n",
      "  Validated 350/713 batches\n",
      "  Validated 400/713 batches\n",
      "  Validated 450/713 batches\n",
      "  Validated 500/713 batches\n",
      "  Validated 550/713 batches\n",
      "  Validated 600/713 batches\n",
      "  Validated 650/713 batches\n",
      "  Validated 700/713 batches\n",
      "\n",
      "Validation Results:\n",
      "  Total edit distance: 11450\n",
      "  Total sequence length: 41392\n",
      "  PER: 27.66%\n",
      "✓ NEW BEST MODEL SAVED!\n",
      "\n",
      "Sample predictions (phonemes):\n",
      "Sample 1:\n",
      "  Truth: Y UW  |  K AE N  |  S IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE Z  |  W EH L  | \n",
      "  Pred:  Y UW  |  K AE D  |  IY  |  DH AH  |  K OW L D  |  AE T  |  DH IH S  |  P OY N T  |  IH S Z  |  W EY  | \n",
      "Sample 2:\n",
      "  Truth: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AA S T  |  D AW N  | \n",
      "  Pred:  AW  |  D AH Z T  |  IH T  |  K IY P  |  DH AH  |  W OW S T  |  T IH D  | \n",
      "Sample 3:\n",
      "  Truth: N AA T  |  T UW  |  K AA N T R AH V ER SH AH L  | \n",
      "  Pred:  N AA D  |   |  T UW  |  K N T S SH AH IY  | \n",
      "------------------------------------------------------------\n",
      "  Batch 100/2018 | Loss: 0.2315\n",
      "  Batch 200/2018 | Loss: 0.3807\n",
      "  Batch 300/2018 | Loss: 0.1791\n",
      "  Batch 400/2018 | Loss: 0.1428\n",
      "  Batch 500/2018 | Loss: 0.2468\n",
      "  Batch 600/2018 | Loss: 0.3234\n",
      "  Batch 700/2018 | Loss: 0.2855\n",
      "  Batch 800/2018 | Loss: 0.2153\n",
      "  Batch 900/2018 | Loss: 0.8959\n",
      "  Batch 1000/2018 | Loss: 0.2208\n",
      "  Batch 1100/2018 | Loss: 0.3092\n",
      "  Batch 1200/2018 | Loss: 0.4611\n",
      "  Batch 1300/2018 | Loss: 0.4166\n",
      "  Batch 1400/2018 | Loss: 0.4486\n",
      "  Batch 1500/2018 | Loss: 0.6951\n",
      "  Batch 1600/2018 | Loss: 0.5999\n",
      "  Batch 1700/2018 | Loss: 0.3144\n",
      "  Batch 1800/2018 | Loss: 0.2711\n",
      "  Batch 1900/2018 | Loss: 0.7301\n",
      "  Batch 2000/2018 | Loss: 0.5675\n",
      "\n",
      "EPOCH 16/30 | Avg Loss: 0.4174\n",
      "  Batch 100/2018 | Loss: 0.5682\n",
      "  Batch 200/2018 | Loss: 0.3244\n",
      "  Batch 300/2018 | Loss: 0.2001\n",
      "  Batch 400/2018 | Loss: 0.2520\n",
      "  Batch 500/2018 | Loss: 0.5884\n",
      "  Batch 600/2018 | Loss: 0.4000\n",
      "  Batch 700/2018 | Loss: 0.4886\n",
      "  Batch 800/2018 | Loss: 0.2772\n",
      "  Batch 900/2018 | Loss: 0.1856\n",
      "  Batch 1000/2018 | Loss: 0.2567\n",
      "  Batch 1100/2018 | Loss: 0.2298\n",
      "  Batch 1200/2018 | Loss: 0.1609\n",
      "  Batch 1300/2018 | Loss: 0.4222\n",
      "  Batch 1400/2018 | Loss: 0.1753\n",
      "  Batch 1500/2018 | Loss: 0.4503\n",
      "  Batch 1600/2018 | Loss: 0.3670\n",
      "  Batch 1700/2018 | Loss: 0.4201\n",
      "  Batch 1800/2018 | Loss: 0.4400\n",
      "  Batch 1900/2018 | Loss: 0.1774\n",
      "  Batch 2000/2018 | Loss: 0.2783\n",
      "\n",
      "EPOCH 17/30 | Avg Loss: 0.3734\n",
      "  Batch 100/2018 | Loss: 0.1278\n",
      "  Batch 200/2018 | Loss: 0.4230\n",
      "  Batch 300/2018 | Loss: 0.1834\n",
      "  Batch 400/2018 | Loss: 0.3879\n",
      "  Batch 500/2018 | Loss: 0.4084\n",
      "  Batch 600/2018 | Loss: 0.3713\n",
      "  Batch 700/2018 | Loss: 0.2505\n",
      "  Batch 800/2018 | Loss: 0.4131\n",
      "  Batch 900/2018 | Loss: 0.4563\n",
      "  Batch 1000/2018 | Loss: 0.2895\n",
      "  Batch 1100/2018 | Loss: 0.1197\n",
      "  Batch 1200/2018 | Loss: 0.2530\n",
      "  Batch 1300/2018 | Loss: 0.5578\n",
      "  Batch 1400/2018 | Loss: 0.3528\n",
      "  Batch 1500/2018 | Loss: 0.1381\n",
      "  Batch 1600/2018 | Loss: 0.5123\n",
      "  Batch 1700/2018 | Loss: 0.2758\n",
      "  Batch 1800/2018 | Loss: 0.3204\n",
      "  Batch 1900/2018 | Loss: 0.1888\n",
      "  Batch 2000/2018 | Loss: 0.4921\n",
      "\n",
      "EPOCH 18/30 | Avg Loss: 0.3356\n",
      "\n",
      "Running full validation...\n",
      "Starting validation...\n",
      "  Validated 50/713 batches\n",
      "  Validated 100/713 batches\n",
      "  Validated 150/713 batches\n",
      "  Validated 200/713 batches\n",
      "  Validated 250/713 batches\n",
      "  Validated 300/713 batches\n",
      "  Validated 350/713 batches\n",
      "  Validated 400/713 batches\n",
      "  Validated 450/713 batches\n",
      "  Validated 500/713 batches\n",
      "  Validated 550/713 batches\n",
      "  Validated 600/713 batches\n",
      "  Validated 650/713 batches\n",
      "  Validated 700/713 batches\n",
      "\n",
      "Validation Results:\n",
      "  Total edit distance: 10647\n",
      "  Total sequence length: 41392\n",
      "  PER: 25.72%\n",
      "✓ NEW BEST MODEL SAVED!\n",
      "\n",
      "Sample predictions (phonemes):\n",
      "Sample 1:\n",
      "  Truth: Y UW  |  K AE N  |  S IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE Z  |  W EH L  | \n",
      "  Pred:  Y UW  |  K AE N  |  SH IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  IH Z  |  W EH L  | \n",
      "Sample 2:\n",
      "  Truth: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AA S T  |  D AW N  | \n",
      "  Pred:  HH AW  |  D AH Z T  |  IH T  |  K IY P  |  DH AH  |  G OW T  |  D IH D  | \n",
      "Sample 3:\n",
      "  Truth: N AA T  |  T UW  |  K AA N T R AH V ER SH AH L  | \n",
      "  Pred:  N AA T  |  T UW  |  IH AE N K UW UW SH AH  | \n",
      "------------------------------------------------------------\n",
      "  Batch 100/2018 | Loss: 0.2210\n",
      "  Batch 200/2018 | Loss: 0.2212\n",
      "  Batch 300/2018 | Loss: 0.3199\n",
      "  Batch 400/2018 | Loss: 0.2195\n",
      "  Batch 500/2018 | Loss: 0.3319\n",
      "  Batch 600/2018 | Loss: 0.3909\n",
      "  Batch 700/2018 | Loss: 0.5342\n",
      "  Batch 800/2018 | Loss: 0.2675\n",
      "  Batch 900/2018 | Loss: 0.2429\n",
      "  Batch 1000/2018 | Loss: 0.4771\n",
      "  Batch 1100/2018 | Loss: 0.1389\n",
      "  Batch 1200/2018 | Loss: 0.1859\n",
      "  Batch 1300/2018 | Loss: 0.2164\n",
      "  Batch 1400/2018 | Loss: 0.2450\n",
      "  Batch 1500/2018 | Loss: 0.3307\n",
      "  Batch 1600/2018 | Loss: 0.4180\n",
      "  Batch 1700/2018 | Loss: 0.2641\n",
      "  Batch 1800/2018 | Loss: 0.5564\n",
      "  Batch 1900/2018 | Loss: 0.2747\n",
      "  Batch 2000/2018 | Loss: 0.2131\n",
      "\n",
      "EPOCH 19/30 | Avg Loss: 0.2950\n",
      "  Batch 100/2018 | Loss: 0.3910\n",
      "  Batch 200/2018 | Loss: 0.4086\n",
      "  Batch 300/2018 | Loss: 0.2294\n",
      "  Batch 400/2018 | Loss: 0.3033\n",
      "  Batch 500/2018 | Loss: 0.2121\n",
      "  Batch 600/2018 | Loss: 0.1481\n",
      "  Batch 700/2018 | Loss: 0.3191\n",
      "  Batch 800/2018 | Loss: 0.2427\n",
      "  Batch 900/2018 | Loss: 0.3513\n",
      "  Batch 1000/2018 | Loss: 0.1122\n",
      "  Batch 1100/2018 | Loss: 0.2388\n",
      "  Batch 1200/2018 | Loss: 0.4365\n",
      "  Batch 1300/2018 | Loss: 0.0664\n",
      "  Batch 1400/2018 | Loss: 0.3578\n",
      "  Batch 1500/2018 | Loss: 0.2604\n",
      "  Batch 1600/2018 | Loss: 0.2895\n",
      "  Batch 1700/2018 | Loss: 0.3048\n",
      "  Batch 1800/2018 | Loss: 0.1226\n",
      "  Batch 1900/2018 | Loss: 0.3036\n",
      "  Batch 2000/2018 | Loss: 0.3709\n",
      "\n",
      "EPOCH 20/30 | Avg Loss: 0.2672\n",
      "  Batch 100/2018 | Loss: 0.1079\n",
      "  Batch 200/2018 | Loss: 0.1073\n",
      "  Batch 300/2018 | Loss: 0.1733\n",
      "  Batch 400/2018 | Loss: 0.1404\n",
      "  Batch 500/2018 | Loss: 0.3538\n",
      "  Batch 600/2018 | Loss: 0.2134\n",
      "  Batch 700/2018 | Loss: 0.1408\n",
      "  Batch 800/2018 | Loss: 0.2123\n",
      "  Batch 900/2018 | Loss: 0.0714\n",
      "  Batch 1000/2018 | Loss: 0.2331\n",
      "  Batch 1100/2018 | Loss: 0.3131\n",
      "  Batch 1200/2018 | Loss: 0.2952\n",
      "  Batch 1300/2018 | Loss: 0.2327\n",
      "  Batch 1400/2018 | Loss: 0.4667\n",
      "  Batch 1500/2018 | Loss: 0.4716\n",
      "  Batch 1600/2018 | Loss: 0.0654\n",
      "  Batch 1700/2018 | Loss: 0.3387\n",
      "  Batch 1800/2018 | Loss: 0.1047\n",
      "  Batch 1900/2018 | Loss: 0.1274\n",
      "  Batch 2000/2018 | Loss: 0.2283\n",
      "\n",
      "EPOCH 21/30 | Avg Loss: 0.2287\n",
      "\n",
      "Running full validation...\n",
      "Starting validation...\n",
      "  Validated 50/713 batches\n",
      "  Validated 100/713 batches\n",
      "  Validated 150/713 batches\n",
      "  Validated 200/713 batches\n",
      "  Validated 250/713 batches\n",
      "  Validated 300/713 batches\n",
      "  Validated 350/713 batches\n",
      "  Validated 400/713 batches\n",
      "  Validated 450/713 batches\n",
      "  Validated 500/713 batches\n",
      "  Validated 550/713 batches\n",
      "  Validated 600/713 batches\n",
      "  Validated 650/713 batches\n",
      "  Validated 700/713 batches\n",
      "\n",
      "Validation Results:\n",
      "  Total edit distance: 10045\n",
      "  Total sequence length: 41392\n",
      "  PER: 24.27%\n",
      "✓ NEW BEST MODEL SAVED!\n",
      "\n",
      "Sample predictions (phonemes):\n",
      "Sample 1:\n",
      "  Truth: Y UW  |  K AE N  |  S IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE Z  |  W EH L  | \n",
      "  Pred:  Y UW  |  K AE N  |  M IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  S  |  W EH L  | \n",
      "Sample 2:\n",
      "  Truth: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AA S T  |  D AW N  | \n",
      "  Pred:  HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K OW S T  |  D D  | \n",
      "Sample 3:\n",
      "  Truth: N AA T  |  T UW  |  K AA N T R AH V ER SH AH L  | \n",
      "  Pred:  N AA T  |  T UW  |  EH AE K CH UW UW SH L AH  | \n",
      "------------------------------------------------------------\n",
      "  Batch 100/2018 | Loss: 0.2029\n",
      "  Batch 200/2018 | Loss: 0.0938\n",
      "  Batch 300/2018 | Loss: 0.2194\n",
      "  Batch 400/2018 | Loss: 0.2400\n",
      "  Batch 500/2018 | Loss: 0.2424\n",
      "  Batch 600/2018 | Loss: 0.0450\n",
      "  Batch 700/2018 | Loss: 0.2042\n",
      "  Batch 800/2018 | Loss: 0.2667\n",
      "  Batch 900/2018 | Loss: 0.1830\n",
      "  Batch 1000/2018 | Loss: 0.4119\n",
      "  Batch 1100/2018 | Loss: 0.1478\n",
      "  Batch 1200/2018 | Loss: 0.1336\n",
      "  Batch 1300/2018 | Loss: 0.0967\n",
      "  Batch 1400/2018 | Loss: 0.3877\n",
      "  Batch 1500/2018 | Loss: 0.1370\n",
      "  Batch 1600/2018 | Loss: 0.0745\n",
      "  Batch 1700/2018 | Loss: 0.2580\n",
      "  Batch 1800/2018 | Loss: 0.4517\n",
      "  Batch 1900/2018 | Loss: 0.0407\n",
      "  Batch 2000/2018 | Loss: 0.2149\n",
      "\n",
      "EPOCH 22/30 | Avg Loss: 0.2023\n",
      "  Batch 100/2018 | Loss: 0.0312\n",
      "  Batch 200/2018 | Loss: 0.1900\n",
      "  Batch 300/2018 | Loss: 0.3171\n",
      "  Batch 400/2018 | Loss: 0.1130\n",
      "  Batch 500/2018 | Loss: 0.1401\n",
      "  Batch 600/2018 | Loss: 0.1005\n",
      "  Batch 700/2018 | Loss: 0.1887\n",
      "  Batch 800/2018 | Loss: 0.1571\n",
      "  Batch 900/2018 | Loss: 0.1267\n",
      "  Batch 1000/2018 | Loss: 0.1395\n",
      "  Batch 1100/2018 | Loss: 0.1985\n",
      "  Batch 1200/2018 | Loss: 0.1617\n",
      "  Batch 1300/2018 | Loss: 0.1769\n",
      "  Batch 1400/2018 | Loss: 0.4586\n",
      "  Batch 1500/2018 | Loss: 0.0835\n",
      "  Batch 1600/2018 | Loss: 0.3480\n",
      "  Batch 1700/2018 | Loss: 0.1228\n",
      "  Batch 1800/2018 | Loss: 0.2218\n",
      "  Batch 1900/2018 | Loss: 0.3231\n",
      "  Batch 2000/2018 | Loss: 0.1179\n",
      "\n",
      "EPOCH 23/30 | Avg Loss: 0.1809\n",
      "  Batch 100/2018 | Loss: 0.0714\n",
      "  Batch 200/2018 | Loss: 0.2779\n",
      "  Batch 300/2018 | Loss: 0.2197\n",
      "  Batch 400/2018 | Loss: 0.1050\n",
      "  Batch 500/2018 | Loss: 0.1026\n",
      "  Batch 600/2018 | Loss: 0.1310\n",
      "  Batch 700/2018 | Loss: 0.2042\n",
      "  Batch 800/2018 | Loss: 0.1485\n",
      "  Batch 900/2018 | Loss: 0.1887\n",
      "  Batch 1000/2018 | Loss: 0.0567\n",
      "  Batch 1100/2018 | Loss: 0.1516\n",
      "  Batch 1200/2018 | Loss: 0.0646\n",
      "  Batch 1300/2018 | Loss: 0.1753\n",
      "  Batch 1400/2018 | Loss: 0.2709\n",
      "  Batch 1500/2018 | Loss: 0.1420\n",
      "  Batch 1600/2018 | Loss: 0.6986\n",
      "  Batch 1700/2018 | Loss: 0.0687\n",
      "  Batch 1800/2018 | Loss: 0.2876\n",
      "  Batch 1900/2018 | Loss: 0.2064\n",
      "  Batch 2000/2018 | Loss: 0.1340\n",
      "\n",
      "EPOCH 24/30 | Avg Loss: 0.1589\n",
      "\n",
      "Running full validation...\n",
      "Starting validation...\n",
      "  Validated 50/713 batches\n",
      "  Validated 100/713 batches\n",
      "  Validated 150/713 batches\n",
      "  Validated 200/713 batches\n",
      "  Validated 250/713 batches\n",
      "  Validated 300/713 batches\n",
      "  Validated 350/713 batches\n",
      "  Validated 400/713 batches\n",
      "  Validated 450/713 batches\n",
      "  Validated 500/713 batches\n",
      "  Validated 550/713 batches\n",
      "  Validated 600/713 batches\n",
      "  Validated 650/713 batches\n",
      "  Validated 700/713 batches\n",
      "\n",
      "Validation Results:\n",
      "  Total edit distance: 9576\n",
      "  Total sequence length: 41392\n",
      "  PER: 23.13%\n",
      "✓ NEW BEST MODEL SAVED!\n",
      "\n",
      "Sample predictions (phonemes):\n",
      "Sample 1:\n",
      "  Truth: Y UW  |  K AE N  |  S IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE Z  |  W EH L  | \n",
      "  Pred:  Y UW  |  K AE N  |  M IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE Z  |  W EH L  | \n",
      "Sample 2:\n",
      "  Truth: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AA S T  |  D AW N  | \n",
      "  Pred:  HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K OW T  |  D AW D  | \n",
      "Sample 3:\n",
      "  Truth: N AA T  |  T UW  |  K AA N T R AH V ER SH AH L  | \n",
      "  Pred:  N AA T  |  T UW  |  K N UW UW SH AH  | \n",
      "------------------------------------------------------------\n",
      "  Batch 100/2018 | Loss: 0.2686\n",
      "  Batch 200/2018 | Loss: 0.0797\n",
      "  Batch 300/2018 | Loss: 0.2187\n",
      "  Batch 400/2018 | Loss: 0.1780\n",
      "  Batch 500/2018 | Loss: 0.1284\n",
      "  Batch 600/2018 | Loss: 0.1387\n",
      "  Batch 700/2018 | Loss: 0.1204\n",
      "  Batch 800/2018 | Loss: 0.1676\n",
      "  Batch 900/2018 | Loss: 0.0651\n",
      "  Batch 1000/2018 | Loss: 0.1724\n",
      "  Batch 1100/2018 | Loss: 0.1213\n",
      "  Batch 1200/2018 | Loss: 0.0593\n",
      "  Batch 1300/2018 | Loss: 0.0555\n",
      "  Batch 1400/2018 | Loss: 0.0460\n",
      "  Batch 1500/2018 | Loss: 0.0427\n",
      "  Batch 1600/2018 | Loss: 0.1985\n",
      "  Batch 1700/2018 | Loss: 0.1212\n",
      "  Batch 1800/2018 | Loss: 0.1326\n",
      "  Batch 1900/2018 | Loss: 0.0798\n",
      "  Batch 2000/2018 | Loss: 0.0236\n",
      "\n",
      "EPOCH 25/30 | Avg Loss: 0.1402\n",
      "  Batch 100/2018 | Loss: 0.0176\n",
      "  Batch 200/2018 | Loss: 0.1037\n",
      "  Batch 300/2018 | Loss: 0.0645\n",
      "  Batch 400/2018 | Loss: 0.0519\n",
      "  Batch 500/2018 | Loss: 0.0961\n",
      "  Batch 600/2018 | Loss: 0.1604\n",
      "  Batch 700/2018 | Loss: 0.1337\n",
      "  Batch 800/2018 | Loss: 0.1337\n",
      "  Batch 900/2018 | Loss: 0.1033\n",
      "  Batch 1000/2018 | Loss: 0.0843\n",
      "  Batch 1100/2018 | Loss: 0.0302\n",
      "  Batch 1200/2018 | Loss: 0.0483\n",
      "  Batch 1300/2018 | Loss: 0.0827\n",
      "  Batch 1400/2018 | Loss: 0.0122\n",
      "  Batch 1500/2018 | Loss: 0.0667\n",
      "  Batch 1600/2018 | Loss: 0.1576\n",
      "  Batch 1700/2018 | Loss: 0.0454\n",
      "  Batch 1800/2018 | Loss: 0.1355\n",
      "  Batch 1900/2018 | Loss: 0.1150\n",
      "  Batch 2000/2018 | Loss: 0.1194\n",
      "\n",
      "EPOCH 26/30 | Avg Loss: 0.1276\n",
      "\n",
      "Running full validation...\n",
      "Starting validation...\n",
      "  Validated 50/713 batches\n",
      "  Validated 100/713 batches\n",
      "  Validated 150/713 batches\n",
      "  Validated 200/713 batches\n",
      "  Validated 250/713 batches\n",
      "  Validated 300/713 batches\n",
      "  Validated 350/713 batches\n",
      "  Validated 400/713 batches\n",
      "  Validated 450/713 batches\n",
      "  Validated 500/713 batches\n",
      "  Validated 550/713 batches\n",
      "  Validated 600/713 batches\n",
      "  Validated 650/713 batches\n",
      "  Validated 700/713 batches\n",
      "\n",
      "Validation Results:\n",
      "  Total edit distance: 9399\n",
      "  Total sequence length: 41392\n",
      "  PER: 22.71%\n",
      "✓ NEW BEST MODEL SAVED!\n",
      "\n",
      "Sample predictions (phonemes):\n",
      "Sample 1:\n",
      "  Truth: Y UW  |  K AE N  |  S IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE Z  |  W EH L  | \n",
      "  Pred:  Y UW  |  K AE N  |  M IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P AY N T  |  HH AE IH S Z  |  W EH L  | \n",
      "Sample 2:\n",
      "  Truth: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AA S T  |  D AW N  | \n",
      "  Pred:  HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K OW T  |  D D  | \n",
      "Sample 3:\n",
      "  Truth: N AA T  |  T UW  |  K AA N T R AH V ER SH AH L  | \n",
      "  Pred:  N AA T  |  T UW  |  K AE N UW UW SH AH L  | \n",
      "------------------------------------------------------------\n",
      "  Batch 100/2018 | Loss: 0.0836\n",
      "  Batch 200/2018 | Loss: 0.1409\n",
      "  Batch 300/2018 | Loss: 0.0843\n",
      "  Batch 400/2018 | Loss: 0.1441\n",
      "  Batch 500/2018 | Loss: 0.1429\n",
      "  Batch 600/2018 | Loss: 0.1759\n",
      "  Batch 700/2018 | Loss: 0.0863\n",
      "  Batch 800/2018 | Loss: 0.1082\n",
      "  Batch 900/2018 | Loss: 0.0979\n",
      "  Batch 1000/2018 | Loss: 0.1618\n",
      "  Batch 1100/2018 | Loss: 0.0544\n",
      "  Batch 1200/2018 | Loss: 0.0563\n",
      "  Batch 1300/2018 | Loss: 0.1633\n",
      "  Batch 1400/2018 | Loss: 0.1599\n",
      "  Batch 1500/2018 | Loss: 0.2069\n",
      "  Batch 1600/2018 | Loss: 0.1420\n",
      "  Batch 1700/2018 | Loss: 0.0670\n",
      "  Batch 1800/2018 | Loss: 0.0965\n",
      "  Batch 1900/2018 | Loss: 0.1993\n",
      "  Batch 2000/2018 | Loss: 0.1038\n",
      "\n",
      "EPOCH 27/30 | Avg Loss: 0.1170\n",
      "\n",
      "Running full validation...\n",
      "Starting validation...\n",
      "  Validated 50/713 batches\n",
      "  Validated 100/713 batches\n",
      "  Validated 150/713 batches\n",
      "  Validated 200/713 batches\n",
      "  Validated 250/713 batches\n",
      "  Validated 300/713 batches\n",
      "  Validated 350/713 batches\n",
      "  Validated 400/713 batches\n",
      "  Validated 450/713 batches\n",
      "  Validated 500/713 batches\n",
      "  Validated 550/713 batches\n",
      "  Validated 600/713 batches\n",
      "  Validated 650/713 batches\n",
      "  Validated 700/713 batches\n",
      "\n",
      "Validation Results:\n",
      "  Total edit distance: 9450\n",
      "  Total sequence length: 41392\n",
      "  PER: 22.83%\n",
      "\n",
      "Sample predictions (phonemes):\n",
      "Sample 1:\n",
      "  Truth: Y UW  |  K AE N  |  S IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE Z  |  W EH L  | \n",
      "  Pred:  Y UW  |  K AE N  |  M IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  S Z  |  W EH L  | \n",
      "Sample 2:\n",
      "  Truth: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AA S T  |  D AW N  | \n",
      "  Pred:  HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K OW T  |  D D  | \n",
      "Sample 3:\n",
      "  Truth: N AA T  |  T UW  |  K AA N T R AH V ER SH AH L  | \n",
      "  Pred:  N AA T  |  T UW  |  K AE N UW UW SH AH L  | \n",
      "------------------------------------------------------------\n",
      "  Batch 100/2018 | Loss: 0.0560\n",
      "  Batch 200/2018 | Loss: 0.1554\n",
      "  Batch 300/2018 | Loss: 0.1453\n",
      "  Batch 400/2018 | Loss: 0.2549\n",
      "  Batch 500/2018 | Loss: 0.2397\n",
      "  Batch 600/2018 | Loss: 0.1049\n",
      "  Batch 700/2018 | Loss: 0.1179\n",
      "  Batch 800/2018 | Loss: 0.0804\n",
      "  Batch 900/2018 | Loss: 0.0308\n",
      "  Batch 1000/2018 | Loss: 0.1098\n",
      "  Batch 1100/2018 | Loss: 0.0952\n",
      "  Batch 1200/2018 | Loss: 0.0910\n",
      "  Batch 1300/2018 | Loss: 0.1208\n",
      "  Batch 1400/2018 | Loss: 0.0471\n",
      "  Batch 1500/2018 | Loss: 0.1414\n",
      "  Batch 1600/2018 | Loss: 0.1322\n",
      "  Batch 1700/2018 | Loss: 0.0688\n",
      "  Batch 1800/2018 | Loss: 0.5124\n",
      "  Batch 1900/2018 | Loss: 0.0713\n",
      "  Batch 2000/2018 | Loss: 0.0605\n",
      "\n",
      "EPOCH 28/30 | Avg Loss: 0.1115\n",
      "\n",
      "Running full validation...\n",
      "Starting validation...\n",
      "  Validated 50/713 batches\n",
      "  Validated 100/713 batches\n",
      "  Validated 150/713 batches\n",
      "  Validated 200/713 batches\n",
      "  Validated 250/713 batches\n",
      "  Validated 300/713 batches\n",
      "  Validated 350/713 batches\n",
      "  Validated 400/713 batches\n",
      "  Validated 450/713 batches\n",
      "  Validated 500/713 batches\n",
      "  Validated 550/713 batches\n",
      "  Validated 600/713 batches\n",
      "  Validated 650/713 batches\n",
      "  Validated 700/713 batches\n",
      "\n",
      "Validation Results:\n",
      "  Total edit distance: 9366\n",
      "  Total sequence length: 41392\n",
      "  PER: 22.63%\n",
      "✓ NEW BEST MODEL SAVED!\n",
      "\n",
      "Sample predictions (phonemes):\n",
      "Sample 1:\n",
      "  Truth: Y UW  |  K AE N  |  S IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE Z  |  W EH L  | \n",
      "  Pred:  Y UW  |  K AE N  |  M IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  HH S Z  |  W EH L  | \n",
      "Sample 2:\n",
      "  Truth: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AA S T  |  D AW N  | \n",
      "  Pred:  HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K OW T  |  D D  | \n",
      "Sample 3:\n",
      "  Truth: N AA T  |  T UW  |  K AA N T R AH V ER SH AH L  | \n",
      "  Pred:  N AA T  |  T UW  |  K AE N UW UW SH AH L  | \n",
      "------------------------------------------------------------\n",
      "  Batch 100/2018 | Loss: 0.2243\n",
      "  Batch 200/2018 | Loss: 0.5734\n",
      "  Batch 300/2018 | Loss: 0.1009\n",
      "  Batch 400/2018 | Loss: 0.1181\n",
      "  Batch 500/2018 | Loss: 0.0707\n",
      "  Batch 600/2018 | Loss: 0.0729\n",
      "  Batch 700/2018 | Loss: 0.1615\n",
      "  Batch 800/2018 | Loss: 0.0786\n",
      "  Batch 900/2018 | Loss: 0.0943\n",
      "  Batch 1000/2018 | Loss: 0.0438\n",
      "  Batch 1100/2018 | Loss: 0.0268\n",
      "  Batch 1200/2018 | Loss: 0.3233\n",
      "  Batch 1300/2018 | Loss: 0.2395\n",
      "  Batch 1400/2018 | Loss: 0.0630\n",
      "  Batch 1500/2018 | Loss: 0.0389\n",
      "  Batch 1600/2018 | Loss: 0.1049\n",
      "  Batch 1700/2018 | Loss: 0.0652\n",
      "  Batch 1800/2018 | Loss: 0.0870\n",
      "  Batch 1900/2018 | Loss: 0.0500\n",
      "  Batch 2000/2018 | Loss: 0.0201\n",
      "\n",
      "EPOCH 29/30 | Avg Loss: 0.1069\n",
      "\n",
      "Running full validation...\n",
      "Starting validation...\n",
      "  Validated 50/713 batches\n",
      "  Validated 100/713 batches\n",
      "  Validated 150/713 batches\n",
      "  Validated 200/713 batches\n",
      "  Validated 250/713 batches\n",
      "  Validated 300/713 batches\n",
      "  Validated 350/713 batches\n",
      "  Validated 400/713 batches\n",
      "  Validated 450/713 batches\n",
      "  Validated 500/713 batches\n",
      "  Validated 550/713 batches\n",
      "  Validated 600/713 batches\n",
      "  Validated 650/713 batches\n",
      "  Validated 700/713 batches\n",
      "\n",
      "Validation Results:\n",
      "  Total edit distance: 9354\n",
      "  Total sequence length: 41392\n",
      "  PER: 22.60%\n",
      "✓ NEW BEST MODEL SAVED!\n",
      "\n",
      "Sample predictions (phonemes):\n",
      "Sample 1:\n",
      "  Truth: Y UW  |  K AE N  |  S IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE Z  |  W EH L  | \n",
      "  Pred:  Y UW  |  K AE N  |  M IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P N T  |  HH AE IH S Z  |  W EH L  | \n",
      "Sample 2:\n",
      "  Truth: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AA S T  |  D AW N  | \n",
      "  Pred:  HH AW  |  D AH Z Z  |  IH T  |  K IY P  |  DH AH  |  K OW T  |  D D  | \n",
      "Sample 3:\n",
      "  Truth: N AA T  |  T UW  |  K AA N T R AH V ER SH AH L  | \n",
      "  Pred:  N AA T  |  T UW  |  K AE N UW UW SH AH L  | \n",
      "------------------------------------------------------------\n",
      "  Batch 100/2018 | Loss: 0.1758\n",
      "  Batch 200/2018 | Loss: 0.0535\n",
      "  Batch 300/2018 | Loss: 0.0841\n",
      "  Batch 400/2018 | Loss: 0.0543\n",
      "  Batch 500/2018 | Loss: 0.1517\n",
      "  Batch 600/2018 | Loss: 0.0785\n",
      "  Batch 700/2018 | Loss: 0.0803\n",
      "  Batch 800/2018 | Loss: 0.0648\n",
      "  Batch 900/2018 | Loss: 0.0818\n",
      "  Batch 1000/2018 | Loss: 0.1047\n",
      "  Batch 1100/2018 | Loss: 0.1944\n",
      "  Batch 1200/2018 | Loss: 0.0545\n",
      "  Batch 1300/2018 | Loss: 0.0371\n",
      "  Batch 1400/2018 | Loss: 0.0653\n",
      "  Batch 1500/2018 | Loss: 0.0817\n",
      "  Batch 1600/2018 | Loss: 0.0862\n",
      "  Batch 1700/2018 | Loss: 0.0840\n",
      "  Batch 1800/2018 | Loss: 0.0842\n",
      "  Batch 1900/2018 | Loss: 0.1380\n",
      "  Batch 2000/2018 | Loss: 0.0766\n",
      "\n",
      "EPOCH 30/30 | Avg Loss: 0.1039\n",
      "\n",
      "Running full validation...\n",
      "Starting validation...\n",
      "  Validated 50/713 batches\n",
      "  Validated 100/713 batches\n",
      "  Validated 150/713 batches\n",
      "  Validated 200/713 batches\n",
      "  Validated 250/713 batches\n",
      "  Validated 300/713 batches\n",
      "  Validated 350/713 batches\n",
      "  Validated 400/713 batches\n",
      "  Validated 450/713 batches\n",
      "  Validated 500/713 batches\n",
      "  Validated 550/713 batches\n",
      "  Validated 600/713 batches\n",
      "  Validated 650/713 batches\n",
      "  Validated 700/713 batches\n",
      "\n",
      "Validation Results:\n",
      "  Total edit distance: 9345\n",
      "  Total sequence length: 41392\n",
      "  PER: 22.58%\n",
      "✓ NEW BEST MODEL SAVED!\n",
      "\n",
      "Sample predictions (phonemes):\n",
      "Sample 1:\n",
      "  Truth: Y UW  |  K AE N  |  S IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE Z  |  W EH L  | \n",
      "  Pred:  Y UW  |  K AE N  |  M IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P N T  |  HH AE IH S Z  |  W EH L  | \n",
      "Sample 2:\n",
      "  Truth: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AA S T  |  D AW N  | \n",
      "  Pred:  HH AW  |  D AH Z Z IH T  |  K IY P  |  DH AH  |  K OW T  |  D D  | \n",
      "Sample 3:\n",
      "  Truth: N AA T  |  T UW  |  K AA N T R AH V ER SH AH L  | \n",
      "  Pred:  N AA T  |  T UW  |  K AE N UW UW SH AH L  | \n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "Training complete!\n",
      "Best PER: 22.58%\n",
      "Model saved: best_model_full_per.pt\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Brain-to-Text CTC Training - Full Dataset + PER\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import editdistance\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --------------------------\n",
    "# CONFIG\n",
    "# --------------------------\n",
    "BASE_PATH = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final\"\n",
    "BATCH_SIZE = 4  # Reduced for full dataset to avoid OOM\n",
    "BATCH_SIZE_VAL = 2\n",
    "NUM_WORKERS = 2\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 5e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "SAVE_PATH = \"best_model_full_per.pt\"\n",
    "\n",
    "# Model architecture\n",
    "D_MODEL = 256\n",
    "NHEAD = 8\n",
    "NUM_LAYERS = 4\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# NO downsampling, NO max sequence length limit\n",
    "DOWNSAMPLE_FACTOR = 1  # No downsampling\n",
    "MAX_SEQ_LEN = None  # No length cap\n",
    "\n",
    "# Use ALL data - no subset limits\n",
    "MAX_TRAIN_TRIALS = None  # Use all training trials\n",
    "MAX_VAL_TRIALS = None  # Use all validation trials\n",
    "\n",
    "# --------------------------\n",
    "# Phoneme Vocab \n",
    "# --------------------------\n",
    "LOGIT_TO_PHONEME = [\n",
    "    \"BLANK\",  # index 0\n",
    "    \"AA\",\n",
    "    \"AE\",\n",
    "    \"AH\",\n",
    "    \"AO\",\n",
    "    \"AW\",\n",
    "    \"AY\",\n",
    "    \"B\",\n",
    "    \"CH\",\n",
    "    \"D\",\n",
    "    \"DH\",\n",
    "    \"EH\",\n",
    "    \"ER\",\n",
    "    \"EY\",\n",
    "    \"F\",\n",
    "    \"G\",\n",
    "    \"HH\",\n",
    "    \"IH\",\n",
    "    \"IY\",\n",
    "    \"JH\",\n",
    "    \"K\",\n",
    "    \"L\",\n",
    "    \"M\",\n",
    "    \"N\",\n",
    "    \"NG\",\n",
    "    \"OW\",\n",
    "    \"OY\",\n",
    "    \"P\",\n",
    "    \"R\",\n",
    "    \"S\",\n",
    "    \"SH\",\n",
    "    \"T\",\n",
    "    \"TH\",\n",
    "    \"UH\",\n",
    "    \"UW\",\n",
    "    \"V\",\n",
    "    \"W\",\n",
    "    \"Y\",\n",
    "    \"Z\",\n",
    "    \"ZH\",\n",
    "    \" | \",  # index 40 - silence/word boundary\n",
    "]\n",
    "\n",
    "VOCAB_SIZE = len(LOGIT_TO_PHONEME)  # 41 classes (including BLANK)\n",
    "phoneme_to_idx = {p: i for i, p in enumerate(LOGIT_TO_PHONEME)}\n",
    "idx_to_phoneme = {i: p for i, p in enumerate(LOGIT_TO_PHONEME)}\n",
    "\n",
    "print(f\"VOCAB_SIZE = {VOCAB_SIZE} (BLANK + 39 phonemes + silence)\")\n",
    "print(f\"Phoneme set: {LOGIT_TO_PHONEME[1:]}\")  # Skip BLANK for display\n",
    "\n",
    "# --------------------------\n",
    "# Full Dataset Loading Functions\n",
    "# --------------------------\n",
    "def get_all_hdf5_files(base_path, split_name):\n",
    "    \"\"\"Recursively find all HDF5 files for a given split\"\"\"\n",
    "    all_files = []\n",
    "    for date_folder in sorted(os.listdir(base_path)):\n",
    "        if date_folder.startswith(\"t15.\"):\n",
    "            fp = os.path.join(base_path, date_folder, f\"data_{split_name}.hdf5\")\n",
    "            if os.path.exists(fp):\n",
    "                all_files.append(fp)\n",
    "    return all_files\n",
    "\n",
    "def load_full_dataset_info(h5_paths):\n",
    "    \"\"\"\n",
    "    Load metadata from all HDF5 files to determine total dataset size\n",
    "    Returns: list of (file_path, key) tuples for all valid trials\n",
    "    \"\"\"\n",
    "    all_trials = []\n",
    "    total_trials = 0\n",
    "    \n",
    "    for h5_path in h5_paths:\n",
    "        if not os.path.exists(h5_path):\n",
    "            continue\n",
    "            \n",
    "        with h5py.File(h5_path, \"r\") as f:\n",
    "            file_trials = 0\n",
    "            for k in f.keys():\n",
    "                grp = f[k]\n",
    "                # Check if trial has seq_class_ids (phoneme labels)\n",
    "                if \"seq_class_ids\" in grp:\n",
    "                    all_trials.append((h5_path, k))\n",
    "                    file_trials += 1\n",
    "            \n",
    "            print(f\"  {os.path.basename(h5_path)}: {file_trials} trials\")\n",
    "            total_trials += file_trials\n",
    "    \n",
    "    print(f\"\\nTotal trials found: {total_trials}\")\n",
    "    return all_trials\n",
    "\n",
    "# --------------------------\n",
    "# Dataset (Full Data, No Downsampling)\n",
    "# --------------------------\n",
    "class Brain2TextDatasetFull(Dataset):\n",
    "    def __init__(self, trial_list, max_trials=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            trial_list: list of (file_path, key) tuples\n",
    "            max_trials: optional limit on number of trials (None = use all)\n",
    "        \"\"\"\n",
    "        self.trials = trial_list if max_trials is None else trial_list[:max_trials]\n",
    "        self.file_cache = {}  # Cache open file handles\n",
    "        print(f\"Dataset initialized with {len(self.trials)} trials\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trials)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path, key = self.trials[idx]\n",
    "        \n",
    "        # Open file (or use cached handle)\n",
    "        if file_path not in self.file_cache:\n",
    "            self.file_cache[file_path] = h5py.File(file_path, \"r\")\n",
    "        \n",
    "        f = self.file_cache[file_path]\n",
    "        grp = f[key]\n",
    "        \n",
    "        # Load neural features - NO downsampling, NO length cap\n",
    "        x = grp[\"input_features\"][()]  # (T, 512)\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        \n",
    "        # Load phoneme target (seq_class_ids)\n",
    "        # These are ALREADY phoneme indices from the dataset\n",
    "        if \"seq_class_ids\" in grp:\n",
    "            seq_class_ids = grp[\"seq_class_ids\"][()]\n",
    "            seq_len = grp.attrs.get(\"seq_len\", len(seq_class_ids))\n",
    "            \n",
    "            # Extract valid phoneme sequence (up to seq_len, remove padding)\n",
    "            phoneme_seq = seq_class_ids[:seq_len]\n",
    "            \n",
    "            # Convert to tensor - these are already phoneme indices\n",
    "            y = torch.tensor(phoneme_seq, dtype=torch.long)\n",
    "        else:\n",
    "            # Fallback: empty sequence\n",
    "            y = torch.tensor([], dtype=torch.long)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __del__(self):\n",
    "        # Close all cached file handles\n",
    "        for f in self.file_cache.values():\n",
    "            try:\n",
    "                f.close()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "def ctc_collate(batch):\n",
    "    \"\"\"Collate function for CTC loss\"\"\"\n",
    "    xs, ys = zip(*batch)\n",
    "    x_lens = torch.tensor([len(x) for x in xs], dtype=torch.long)\n",
    "    y_lens = torch.tensor([len(y) for y in ys], dtype=torch.long)\n",
    "    X = nn.utils.rnn.pad_sequence(xs, batch_first=True)\n",
    "    Y = torch.cat(ys)\n",
    "    return X, Y, x_lens, y_lens\n",
    "\n",
    "# --------------------------\n",
    "# Model\n",
    "# --------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=10000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class BrainTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(512, D_MODEL),\n",
    "            nn.LayerNorm(D_MODEL),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(DROPOUT)\n",
    "        )\n",
    "        self.pos = PositionalEncoding(D_MODEL)\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=D_MODEL, nhead=NHEAD, dim_feedforward=D_MODEL*4,\n",
    "            dropout=DROPOUT, activation='gelu', batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(layer, NUM_LAYERS)\n",
    "        self.out = nn.Linear(D_MODEL, VOCAB_SIZE)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.proj(x)\n",
    "        x = self.pos(x)\n",
    "        x = self.transformer(x, src_key_padding_mask=mask)\n",
    "        return self.out(x)\n",
    "\n",
    "# --------------------------\n",
    "# Phoneme Error Rate (PER) Calculation\n",
    "# --------------------------\n",
    "def ctc_greedy_decode(logits):\n",
    "    \"\"\"\n",
    "    CTC greedy decoding: argmax -> collapse repeats -> remove blanks\n",
    "    Matches the reference implementation\n",
    "    \n",
    "    Args:\n",
    "        logits: (batch, time, vocab_size) tensor\n",
    "    Returns:\n",
    "        List of phoneme index sequences (one per batch item)\n",
    "    \"\"\"\n",
    "    pred_ids = logits.argmax(-1).cpu().numpy()  # (batch, time)\n",
    "    \n",
    "    decoded_sequences = []\n",
    "    for seq in pred_ids:\n",
    "        # Collapse consecutive duplicates\n",
    "        collapsed = []\n",
    "        prev = -1\n",
    "        for token_id in seq:\n",
    "            if token_id != prev:\n",
    "                collapsed.append(int(token_id))\n",
    "            prev = token_id\n",
    "        \n",
    "        # Remove blanks (index 0)\n",
    "        no_blanks = [tok for tok in collapsed if tok != 0]\n",
    "        decoded_sequences.append(no_blanks)\n",
    "    \n",
    "    return decoded_sequences\n",
    "\n",
    "def calculate_per(predictions, ground_truths):\n",
    "    \"\"\"\n",
    "    Calculate Phoneme Error Rate using edit distance\n",
    "    Matches reference implementation\n",
    "    \n",
    "    Args:\n",
    "        predictions: list of predicted phoneme index sequences\n",
    "        ground_truths: list of ground truth phoneme index sequences\n",
    "    Returns:\n",
    "        per: Phoneme Error Rate as percentage\n",
    "        total_edit_distance: sum of edit distances\n",
    "        total_length: sum of ground truth lengths\n",
    "    \"\"\"\n",
    "    total_edit_distance = 0\n",
    "    total_length = 0\n",
    "    \n",
    "    for pred_seq, true_seq in zip(predictions, ground_truths):\n",
    "        # Calculate edit distance between sequences\n",
    "        edit_dist = editdistance.eval(true_seq, pred_seq)\n",
    "        total_edit_distance += edit_dist\n",
    "        total_length += len(true_seq)\n",
    "    \n",
    "    per = (total_edit_distance / total_length * 100) if total_length > 0 else 100.0\n",
    "    \n",
    "    return per, total_edit_distance, total_length\n",
    "\n",
    "# --------------------------\n",
    "# Validation (Full Dataset)\n",
    "# --------------------------\n",
    "def validate(model, dl):\n",
    "    \"\"\"Validate on full validation set\"\"\"\n",
    "    model.eval()\n",
    "    all_pred_seqs = []\n",
    "    all_true_seqs = []\n",
    "    \n",
    "    print(\"Starting validation...\")\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X, Y, x_len, y_len) in enumerate(dl):\n",
    "            X = X.to(DEVICE)\n",
    "            mask = torch.arange(X.size(1), device=DEVICE)[None, :] >= x_len.to(DEVICE)[:, None]\n",
    "            \n",
    "            logits = model(X, mask)  # (batch, time, vocab_size)\n",
    "            \n",
    "            # CTC greedy decode\n",
    "            pred_seqs = ctc_greedy_decode(logits)\n",
    "            \n",
    "            # Extract ground truth sequences\n",
    "            start = 0\n",
    "            true_seqs = []\n",
    "            for L in y_len:\n",
    "                seq = Y[start:start+L].cpu().numpy().tolist()\n",
    "                true_seqs.append(seq)\n",
    "                start += L\n",
    "            \n",
    "            all_pred_seqs.extend(pred_seqs)\n",
    "            all_true_seqs.extend(true_seqs)\n",
    "            \n",
    "            if (batch_idx + 1) % 50 == 0:\n",
    "                print(f\"  Validated {batch_idx + 1}/{len(dl)} batches\")\n",
    "            \n",
    "            del logits, X, mask\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Calculate PER\n",
    "    per, total_edit_dist, total_len = calculate_per(all_pred_seqs, all_true_seqs)\n",
    "    \n",
    "    print(f\"\\nValidation Results:\")\n",
    "    print(f\"  Total edit distance: {total_edit_dist}\")\n",
    "    print(f\"  Total sequence length: {total_len}\")\n",
    "    print(f\"  PER: {per:.2f}%\")\n",
    "    \n",
    "    # Get sample predictions for display (first 5)\n",
    "    sample_preds = []\n",
    "    sample_truths = []\n",
    "    for i in range(min(5, len(all_pred_seqs))):\n",
    "        pred_phonemes = [idx_to_phoneme[idx] for idx in all_pred_seqs[i] if idx < VOCAB_SIZE]\n",
    "        true_phonemes = [idx_to_phoneme[idx] for idx in all_true_seqs[i] if idx < VOCAB_SIZE]\n",
    "        sample_preds.append(' '.join(pred_phonemes))\n",
    "        sample_truths.append(' '.join(true_phonemes))\n",
    "    \n",
    "    return per, sample_preds, sample_truths\n",
    "\n",
    "# --------------------------\n",
    "# Main Training Loop\n",
    "# --------------------------\n",
    "print(\"=\"*60)\n",
    "print(\"LOADING FULL DATASET...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get all HDF5 files\n",
    "train_files = get_all_hdf5_files(BASE_PATH, \"train\")\n",
    "val_files = get_all_hdf5_files(BASE_PATH, \"val\")\n",
    "\n",
    "print(f\"\\nFound {len(train_files)} training files\")\n",
    "print(f\"Found {len(val_files)} validation files\")\n",
    "\n",
    "# Load trial information\n",
    "print(\"\\nLoading training trials...\")\n",
    "train_trials = load_full_dataset_info(train_files)\n",
    "\n",
    "print(\"\\nLoading validation trials...\")\n",
    "val_trials = load_full_dataset_info(val_files)\n",
    "\n",
    "# Create datasets (full data)\n",
    "train_ds = Brain2TextDatasetFull(train_trials, max_trials=MAX_TRAIN_TRIALS)\n",
    "val_ds = Brain2TextDatasetFull(val_trials, max_trials=MAX_VAL_TRIALS)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dl = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    collate_fn=ctc_collate, num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE_VAL, shuffle=False,\n",
    "    collate_fn=ctc_collate, num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoader created:\")\n",
    "print(f\"  Train batches: {len(train_dl)}\")\n",
    "print(f\"  Val batches: {len(val_dl)}\")\n",
    "\n",
    "# --------------------------\n",
    "# Model + Optimizer\n",
    "# --------------------------\n",
    "model = BrainTransformer().to(DEVICE)\n",
    "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=LEARNING_RATE, epochs=EPOCHS,\n",
    "    steps_per_epoch=len(train_dl), pct_start=0.1, anneal_strategy='cos'\n",
    ")\n",
    "ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "\n",
    "best_per = 100.0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TRAINING ON FULL DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (X, Y, x_len, y_len) in enumerate(train_dl):\n",
    "        X = X.to(DEVICE)\n",
    "        Y = Y.to(DEVICE)\n",
    "        x_len = x_len.to(DEVICE)\n",
    "        y_len = y_len.to(DEVICE)\n",
    "        \n",
    "        mask = torch.arange(X.size(1), device=DEVICE)[None,:] >= x_len[:,None]\n",
    "        \n",
    "        logits = model(X, mask)\n",
    "        log_probs = logits.log_softmax(-1).transpose(0, 1)  # (T, B, C)\n",
    "        \n",
    "        loss = ctc_loss(log_probs, Y, x_len, y_len)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"  Batch {batch_idx + 1}/{len(train_dl)} | Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dl)\n",
    "    print(f\"\\nEPOCH {epoch+1}/{EPOCHS} | Avg Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Validate every 3 epochs or in last 5 epochs\n",
    "    if (epoch+1) % 3 == 0 or epoch >= EPOCHS - 5:\n",
    "        print(\"\\nRunning full validation...\")\n",
    "        val_per, sample_preds, sample_truths = validate(model, val_dl)\n",
    "        \n",
    "        if val_per < best_per:\n",
    "            best_per = val_per\n",
    "            torch.save(model.state_dict(), SAVE_PATH)\n",
    "            print(\"✓ NEW BEST MODEL SAVED!\")\n",
    "        \n",
    "        print(\"\\nSample predictions (phonemes):\")\n",
    "        for i, (truth, pred) in enumerate(zip(sample_truths[:3], sample_preds[:3])):\n",
    "            print(f\"Sample {i+1}:\")\n",
    "            print(f\"  Truth: {truth}\")\n",
    "            print(f\"  Pred:  {pred}\")\n",
    "        print(\"-\"*60)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training complete!\")\n",
    "print(f\"Best PER: {best_per:.2f}%\")\n",
    "print(f\"Model saved: {SAVE_PATH}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "670d2d3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T14:45:14.267518Z",
     "iopub.status.busy": "2025-11-29T14:45:14.266988Z",
     "iopub.status.idle": "2025-11-29T14:45:42.163209Z",
     "shell.execute_reply": "2025-11-29T14:45:42.161854Z"
    },
    "papermill": {
     "duration": 27.934975,
     "end_time": "2025-11-29T14:45:42.164657",
     "exception": false,
     "start_time": "2025-11-29T14:45:14.229682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BRAIN-TO-TEXT WER EVALUATION\n",
      "============================================================\n",
      "\n",
      "Loading validation data...\n",
      "  data_val.hdf5: 35 trials\n",
      "  data_val.hdf5: 49 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 49 trials\n",
      "  data_val.hdf5: 34 trials\n",
      "  data_val.hdf5: 35 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 44 trials\n",
      "  data_val.hdf5: 36 trials\n",
      "  data_val.hdf5: 17 trials\n",
      "  data_val.hdf5: 44 trials\n",
      "  data_val.hdf5: 44 trials\n",
      "  data_val.hdf5: 9 trials\n",
      "  data_val.hdf5: 33 trials\n",
      "  data_val.hdf5: 50 trials\n",
      "  data_val.hdf5: 15 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 20 trials\n",
      "  data_val.hdf5: 44 trials\n",
      "  data_val.hdf5: 34 trials\n",
      "  data_val.hdf5: 50 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 30 trials\n",
      "  data_val.hdf5: 50 trials\n",
      "  data_val.hdf5: 23 trials\n",
      "  data_val.hdf5: 24 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 46 trials\n",
      "  data_val.hdf5: 48 trials\n",
      "  data_val.hdf5: 23 trials\n",
      "  data_val.hdf5: 47 trials\n",
      "  data_val.hdf5: 24 trials\n",
      "  data_val.hdf5: 24 trials\n",
      "  data_val.hdf5: 30 trials\n",
      "  data_val.hdf5: 25 trials\n",
      "\n",
      "Total trials found: 1426\n",
      "Dataset initialized with 1426 trials\n",
      "\n",
      "Loading trained model...\n",
      "✓ Model loaded from /kaggle/input/transformer/other/default/1/best_model_full_per.pt\n",
      "✓ Model has 3,301,417 parameters\n",
      "\n",
      "============================================================\n",
      "Running evaluation...\n",
      "  Processed 100/713 batches\n",
      "  Processed 200/713 batches\n",
      "  Processed 300/713 batches\n",
      "  Processed 400/713 batches\n",
      "  Processed 500/713 batches\n",
      "  Processed 600/713 batches\n",
      "  Processed 700/713 batches\n",
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS\n",
      "============================================================\n",
      "Phoneme Error Rate (PER): 23.90%\n",
      "Word Error Rate (WER): 37.66%\n",
      "Total word errors: 3557\n",
      "Total words: 9445\n",
      "============================================================\n",
      "\n",
      "Sample Predictions (first 5):\n",
      "\n",
      "--- Sample 1 ---\n",
      "Pred Phonemes: Y UW  |  K AE N  |  S IY  |  DH AH  |  K UH D  |  AE T  |  DH IH S  |  P OY N T  |  AE\n",
      "True Phonemes: Y UW  |  K AE N  |  S IY  |  DH AH  |  K OW D  |  AE T  |  DH IH S  |  P OY N T  |  AE\n",
      "Pred Words: you can see the code at this point at will\n",
      "True Words: you can see the code at this point as well\n",
      "\n",
      "--- Sample 2 ---\n",
      "Pred Phonemes: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AH S T  |  AE N  |   | \n",
      "True Phonemes: HH AW  |  D AH Z  |  IH T  |  K IY P  |  DH AH  |  K AA S T  |  D AW N  | \n",
      "Pred Words: how the it keep the what an\n",
      "True Words: how the it keep the cost down\n",
      "\n",
      "--- Sample 3 ---\n",
      "Pred Phonemes: N AA T  |  T UW  |  K AH N AH SH AH L  | \n",
      "True Phonemes: N AA T  |  T UW  |  K AA N T R AH V ER SH AH L  | \n",
      "Pred Words: not to <K_AH_N_AH_SH_AH_L>\n",
      "True Words: not to <K_AA_N_T_R_AH_V_ER_SH_AH_L>\n",
      "\n",
      "--- Sample 4 ---\n",
      "Pred Phonemes: DH AH  |  D T UH R IH L  |  IH N  |  AH  |  JH AH S  |  W AO K  |  T AH EH EH DH ER  | \n",
      "True Phonemes: DH AH  |  JH UH R IY  |  AH N D  |  AH  |  JH AH JH  |  W ER K  |  T AH G EH DH ER  |  AA\n",
      "Pred Words: the <D_T_UH_R_IH_L> in the the for <T_AH_EH_EH_DH_ER> in it\n",
      "True Words: the <JH_UH_R_IY> and the the will <T_AH_G_EH_DH_ER> in it\n",
      "\n",
      "--- Sample 5 ---\n",
      "Pred Phonemes: W ER  |  K W AY T  |  V OW K AH L  |  AH B AW T  |  IH T  |   |   | \n",
      "True Phonemes: W ER  |  K W AY T  |  V OW K AH L  |  AH B AW T  |  IH T  | \n",
      "Pred Words: were what <V_OW_K_AH_L> but it\n",
      "True Words: were what <V_OW_K_AH_L> but it\n",
      "\n",
      "============================================================\n",
      "FINAL RESULTS\n",
      "============================================================\n",
      "PER: 23.90%\n",
      "WER: 37.66%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPLETE WER EVALUATION - All Dependencies Included\n",
    "# Run this in a fresh Kaggle notebook to compute WER on trained model\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import editdistance\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION (Match your training)\n",
    "# ============================================================================\n",
    "BASE_PATH = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final\"\n",
    "MODEL_PATH = \"/kaggle/input/transformer/other/default/1/best_model_full_per.pt\"\n",
    "BATCH_SIZE_VAL = 2\n",
    "NUM_WORKERS = 2\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Model architecture (must match training)\n",
    "VOCAB_SIZE = 41\n",
    "D_MODEL = 256\n",
    "NHEAD = 8\n",
    "NUM_LAYERS = 4\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# Phoneme vocabulary (same as training)\n",
    "LOGIT_TO_PHONEME = [\n",
    "    \"BLANK\",  # index 0\n",
    "    \"AA\", \"AE\", \"AH\", \"AO\", \"AW\", \"AY\", \"B\", \"CH\", \"D\", \"DH\",\n",
    "    \"EH\", \"ER\", \"EY\", \"F\", \"G\", \"HH\", \"IH\", \"IY\", \"JH\", \"K\",\n",
    "    \"L\", \"M\", \"N\", \"NG\", \"OW\", \"OY\", \"P\", \"R\", \"S\", \"SH\",\n",
    "    \"T\", \"TH\", \"UH\", \"UW\", \"V\", \"W\", \"Y\", \"Z\", \"ZH\", \" | \"\n",
    "]\n",
    "idx_to_phoneme = {i: p for i, p in enumerate(LOGIT_TO_PHONEME)}\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING (Same as training)\n",
    "# ============================================================================\n",
    "\n",
    "def get_all_hdf5_files(base_path, split_name):\n",
    "    \"\"\"Recursively find all HDF5 files for a given split\"\"\"\n",
    "    all_files = []\n",
    "    for date_folder in sorted(os.listdir(base_path)):\n",
    "        if date_folder.startswith(\"t15.\"):\n",
    "            fp = os.path.join(base_path, date_folder, f\"data_{split_name}.hdf5\")\n",
    "            if os.path.exists(fp):\n",
    "                all_files.append(fp)\n",
    "    return all_files\n",
    "\n",
    "def load_full_dataset_info(h5_paths):\n",
    "    \"\"\"Load metadata from all HDF5 files\"\"\"\n",
    "    all_trials = []\n",
    "    total_trials = 0\n",
    "    \n",
    "    for h5_path in h5_paths:\n",
    "        if not os.path.exists(h5_path):\n",
    "            continue\n",
    "            \n",
    "        with h5py.File(h5_path, \"r\") as f:\n",
    "            file_trials = 0\n",
    "            for k in f.keys():\n",
    "                grp = f[k]\n",
    "                if \"seq_class_ids\" in grp:\n",
    "                    all_trials.append((h5_path, k))\n",
    "                    file_trials += 1\n",
    "            \n",
    "            print(f\"  {os.path.basename(h5_path)}: {file_trials} trials\")\n",
    "            total_trials += file_trials\n",
    "    \n",
    "    print(f\"\\nTotal trials found: {total_trials}\")\n",
    "    return all_trials\n",
    "\n",
    "class Brain2TextDatasetFull(Dataset):\n",
    "    \"\"\"Dataset loader (same as training)\"\"\"\n",
    "    def __init__(self, trial_list, max_trials=None):\n",
    "        self.trials = trial_list if max_trials is None else trial_list[:max_trials]\n",
    "        self.file_cache = {}\n",
    "        print(f\"Dataset initialized with {len(self.trials)} trials\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trials)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path, key = self.trials[idx]\n",
    "        \n",
    "        if file_path not in self.file_cache:\n",
    "            self.file_cache[file_path] = h5py.File(file_path, \"r\")\n",
    "        \n",
    "        f = self.file_cache[file_path]\n",
    "        grp = f[key]\n",
    "        \n",
    "        # Load neural features\n",
    "        x = grp[\"input_features\"][()]\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        \n",
    "        # Load phoneme target\n",
    "        if \"seq_class_ids\" in grp:\n",
    "            seq_class_ids = grp[\"seq_class_ids\"][()]\n",
    "            seq_len = grp.attrs.get(\"seq_len\", len(seq_class_ids))\n",
    "            phoneme_seq = seq_class_ids[:seq_len]\n",
    "            y = torch.tensor(phoneme_seq, dtype=torch.long)\n",
    "        else:\n",
    "            y = torch.tensor([], dtype=torch.long)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __del__(self):\n",
    "        for f in self.file_cache.values():\n",
    "            try:\n",
    "                f.close()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "def ctc_collate(batch):\n",
    "    \"\"\"Collate function for CTC loss\"\"\"\n",
    "    xs, ys = zip(*batch)\n",
    "    x_lens = torch.tensor([len(x) for x in xs], dtype=torch.long)\n",
    "    y_lens = torch.tensor([len(y) for y in ys], dtype=torch.long)\n",
    "    X = nn.utils.rnn.pad_sequence(xs, batch_first=True)\n",
    "    Y = torch.cat(ys)\n",
    "    return X, Y, x_lens, y_lens\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL ARCHITECTURE (Same as training)\n",
    "# ============================================================================\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=10000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class BrainTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size=41, d_model=256, nhead=8, num_layers=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(512, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.pos = PositionalEncoding(d_model)\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4,\n",
    "            dropout=dropout, activation='gelu', batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(layer, num_layers)\n",
    "        self.out = nn.Linear(d_model, vocab_size)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.proj(x)\n",
    "        x = self.pos(x)\n",
    "        x = self.transformer(x, src_key_padding_mask=mask)\n",
    "        return self.out(x)\n",
    "\n",
    "# ============================================================================\n",
    "# CTC DECODING (Same as training)\n",
    "# ============================================================================\n",
    "\n",
    "def ctc_greedy_decode(logits):\n",
    "    \"\"\"CTC greedy decoding: argmax -> collapse repeats -> remove blanks\"\"\"\n",
    "    pred_ids = logits.argmax(-1).cpu().numpy()\n",
    "    decoded_sequences = []\n",
    "    \n",
    "    for seq in pred_ids:\n",
    "        collapsed = []\n",
    "        prev = -1\n",
    "        for token_id in seq:\n",
    "            if token_id != prev:\n",
    "                collapsed.append(int(token_id))\n",
    "            prev = token_id\n",
    "        no_blanks = [tok for tok in collapsed if tok != 0]\n",
    "        decoded_sequences.append(no_blanks)\n",
    "    \n",
    "    return decoded_sequences\n",
    "\n",
    "def calculate_per(predictions, ground_truths):\n",
    "    \"\"\"Calculate Phoneme Error Rate\"\"\"\n",
    "    total_edit_distance = 0\n",
    "    total_length = 0\n",
    "    \n",
    "    for pred_seq, true_seq in zip(predictions, ground_truths):\n",
    "        edit_dist = editdistance.eval(true_seq, pred_seq)\n",
    "        total_edit_distance += edit_dist\n",
    "        total_length += len(true_seq)\n",
    "    \n",
    "    per = (total_edit_distance / total_length * 100) if total_length > 0 else 100.0\n",
    "    return per, total_edit_distance, total_length\n",
    "\n",
    "# ============================================================================\n",
    "# PHONEME-TO-WORD CONVERSION\n",
    "# ============================================================================\n",
    "\n",
    "class PhonemeDictionary:\n",
    "    \"\"\"Phoneme-to-word dictionary for decoding\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Common words dictionary (phonemes as tuples -> words)\n",
    "        self.phoneme_to_words = {\n",
    "            # Pronouns\n",
    "            ('Y', 'UW'): ['you'],\n",
    "            ('HH', 'IY'): ['he'],\n",
    "            ('SH', 'IY'): ['she'],\n",
    "            ('W', 'IY'): ['we'],\n",
    "            ('DH', 'EY'): ['they'],\n",
    "            ('IH', 'T'): ['it'],\n",
    "            \n",
    "            # Common verbs\n",
    "            ('K', 'AE', 'N'): ['can'],\n",
    "            ('W', 'IH', 'L'): ['will'],\n",
    "            ('HH', 'AE', 'V'): ['have'],\n",
    "            ('W', 'AH', 'Z'): ['was'],\n",
    "            ('W', 'ER'): ['were'],\n",
    "            ('IH', 'Z'): ['is'],\n",
    "            ('S', 'IY'): ['see'],\n",
    "            ('G', 'OW'): ['go'],\n",
    "            ('K', 'AH', 'M'): ['come'],\n",
    "            ('G', 'EH', 'T'): ['get'],\n",
    "            ('M', 'EY', 'K'): ['make'],\n",
    "            ('K', 'IY', 'P'): ['keep'],\n",
    "            \n",
    "            # Articles & Prepositions\n",
    "            ('DH', 'AH'): ['the'],\n",
    "            ('AH'): ['a', 'uh'],\n",
    "            ('AE', 'N'): ['an'],\n",
    "            ('T', 'UW'): ['to', 'too'],\n",
    "            ('AH', 'V'): ['of'],\n",
    "            ('AE', 'T'): ['at'],\n",
    "            ('IH', 'N'): ['in'],\n",
    "            ('AO', 'N'): ['on'],\n",
    "            ('F', 'AO', 'R'): ['for'],\n",
    "            ('AE', 'Z'): ['as'],\n",
    "            \n",
    "            # Demonstratives\n",
    "            ('DH', 'IH', 'S'): ['this'],\n",
    "            ('DH', 'AE', 'T'): ['that'],\n",
    "            \n",
    "            # Conjunctions\n",
    "            ('AE', 'N', 'D'): ['and'],\n",
    "            ('B', 'AH', 'T'): ['but'],\n",
    "            ('AO', 'R'): ['or'],\n",
    "            \n",
    "            # Question words\n",
    "            ('HH', 'AW'): ['how'],\n",
    "            ('W', 'AH', 'T'): ['what'],\n",
    "            ('W', 'EH', 'N'): ['when'],\n",
    "            ('W', 'EH', 'R'): ['where'],\n",
    "            ('HH', 'UW'): ['who'],\n",
    "            ('W', 'AY'): ['why'],\n",
    "            \n",
    "            # Common nouns\n",
    "            ('T', 'AY', 'M'): ['time'],\n",
    "            ('P', 'IY', 'P', 'AH', 'L'): ['people'],\n",
    "            ('K', 'OW', 'D'): ['code'],\n",
    "            ('P', 'OY', 'N', 'T'): ['point'],\n",
    "            ('K', 'AA', 'S', 'T'): ['cost'],\n",
    "            ('D', 'AW', 'N'): ['down'],\n",
    "            \n",
    "            # Adjectives\n",
    "            ('N', 'UW'): ['new'],\n",
    "            ('G', 'UH', 'D'): ['good'],\n",
    "            ('N', 'AA', 'T'): ['not'],\n",
    "            \n",
    "            # Common expressions\n",
    "            ('Y', 'EH', 'S'): ['yes'],\n",
    "            ('N', 'OW'): ['no'],\n",
    "            ('W', 'EH', 'L'): ['well'],\n",
    "        }\n",
    "        \n",
    "        # Word frequencies\n",
    "        self.word_freq = Counter({\n",
    "            'the': 1000000, 'to': 500000, 'and': 450000,\n",
    "            'of': 400000, 'a': 350000, 'in': 300000,\n",
    "            'is': 250000, 'that': 200000, 'for': 180000,\n",
    "            'it': 170000, 'you': 160000, 'can': 150000,\n",
    "            'will': 140000, 'have': 130000, 'this': 120000,\n",
    "            'at': 110000, 'see': 100000, 'what': 95000,\n",
    "            'how': 90000, 'not': 85000, 'code': 50000,\n",
    "        })\n",
    "    \n",
    "    def lookup(self, phoneme_tuple):\n",
    "        \"\"\"Exact dictionary lookup\"\"\"\n",
    "        return self.phoneme_to_words.get(phoneme_tuple, None)\n",
    "    \n",
    "    def fuzzy_match(self, phoneme_tuple, max_edit_dist=2):\n",
    "        \"\"\"Find closest matches using edit distance\"\"\"\n",
    "        if not phoneme_tuple:\n",
    "            return []\n",
    "        \n",
    "        candidates = []\n",
    "        for dict_phonemes, words in self.phoneme_to_words.items():\n",
    "            dist = editdistance.eval(phoneme_tuple, dict_phonemes)\n",
    "            \n",
    "            if dist <= max_edit_dist:\n",
    "                for word in words:\n",
    "                    freq = self.word_freq.get(word, 1)\n",
    "                    score = -dist + np.log(freq) / 10\n",
    "                    candidates.append((word, score, dist))\n",
    "        \n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        return candidates[:5]\n",
    "\n",
    "class PhonemeToWordConverter:\n",
    "    \"\"\"Converts phoneme sequences to word sequences\"\"\"\n",
    "    \n",
    "    def __init__(self, phoneme_dict):\n",
    "        self.phoneme_dict = phoneme_dict\n",
    "        self.silence_token = ' | '\n",
    "    \n",
    "    def convert(self, phoneme_list, use_fuzzy=True):\n",
    "        \"\"\"Convert list of phoneme strings to words\"\"\"\n",
    "        words = []\n",
    "        current_phonemes = []\n",
    "        \n",
    "        for phoneme in phoneme_list:\n",
    "            if phoneme == self.silence_token:\n",
    "                if current_phonemes:\n",
    "                    word = self._phonemes_to_word(tuple(current_phonemes), use_fuzzy)\n",
    "                    if word:\n",
    "                        words.append(word)\n",
    "                    current_phonemes = []\n",
    "            else:\n",
    "                current_phonemes.append(phoneme)\n",
    "        \n",
    "        # Handle last word\n",
    "        if current_phonemes:\n",
    "            word = self._phonemes_to_word(tuple(current_phonemes), use_fuzzy)\n",
    "            if word:\n",
    "                words.append(word)\n",
    "        \n",
    "        return words\n",
    "    \n",
    "    def _phonemes_to_word(self, phoneme_tuple, use_fuzzy=True):\n",
    "        \"\"\"Convert phoneme tuple to single word\"\"\"\n",
    "        # Exact match\n",
    "        matches = self.phoneme_dict.lookup(phoneme_tuple)\n",
    "        if matches:\n",
    "            return max(matches, key=lambda w: self.phoneme_dict.word_freq.get(w, 0))\n",
    "        \n",
    "        # Fuzzy match\n",
    "        if use_fuzzy:\n",
    "            candidates = self.phoneme_dict.fuzzy_match(phoneme_tuple)\n",
    "            if candidates:\n",
    "                return candidates[0][0]\n",
    "        \n",
    "        # Fallback\n",
    "        return '<' + '_'.join(phoneme_tuple) + '>'\n",
    "\n",
    "# ============================================================================\n",
    "# WER CALCULATION\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_wer(predictions, references):\n",
    "    \"\"\"Calculate Word Error Rate\"\"\"\n",
    "    total_errors = 0\n",
    "    total_words = 0\n",
    "    \n",
    "    for pred_words, ref_words in zip(predictions, references):\n",
    "        errors = editdistance.eval(pred_words, ref_words)\n",
    "        total_errors += errors\n",
    "        total_words += len(ref_words)\n",
    "    \n",
    "    wer = (total_errors / total_words * 100) if total_words > 0 else 100.0\n",
    "    return wer, total_errors, total_words\n",
    "\n",
    "# ============================================================================\n",
    "# FULL EVALUATION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_wer(model, dataloader, idx_to_phoneme, device='cuda'):\n",
    "    \"\"\"Evaluate trained model with WER metric\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    phoneme_dict = PhonemeDictionary()\n",
    "    converter = PhonemeToWordConverter(phoneme_dict)\n",
    "    \n",
    "    all_pred_phoneme_seqs = []\n",
    "    all_true_phoneme_seqs = []\n",
    "    all_pred_word_seqs = []\n",
    "    all_true_word_seqs = []\n",
    "    \n",
    "    print(\"Running evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X, Y, x_len, y_len) in enumerate(dataloader):\n",
    "            X = X.to(device)\n",
    "            mask = torch.arange(X.size(1), device=device)[None, :] >= x_len.to(device)[:, None]\n",
    "            \n",
    "            logits = model(X, mask)\n",
    "            pred_seqs = ctc_greedy_decode(logits)\n",
    "            \n",
    "            # Convert predictions to phonemes and words\n",
    "            for pred_indices in pred_seqs:\n",
    "                pred_phonemes = [idx_to_phoneme[idx] for idx in pred_indices if idx < len(idx_to_phoneme)]\n",
    "                pred_words = converter.convert(pred_phonemes, use_fuzzy=True)\n",
    "                \n",
    "                all_pred_phoneme_seqs.append(pred_indices)\n",
    "                all_pred_word_seqs.append(pred_words)\n",
    "            \n",
    "            # Convert ground truth\n",
    "            start = 0\n",
    "            for length in y_len:\n",
    "                true_indices = Y[start:start+length].cpu().numpy().tolist()\n",
    "                true_phonemes = [idx_to_phoneme[idx] for idx in true_indices if idx < len(idx_to_phoneme)]\n",
    "                true_words = converter.convert(true_phonemes, use_fuzzy=True)\n",
    "                \n",
    "                all_true_phoneme_seqs.append(true_indices)\n",
    "                all_true_word_seqs.append(true_words)\n",
    "                start += length\n",
    "            \n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(f\"  Processed {batch_idx + 1}/{len(dataloader)} batches\")\n",
    "            \n",
    "            del logits, X, mask\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    per, _, _ = calculate_per(all_pred_phoneme_seqs, all_true_phoneme_seqs)\n",
    "    wer, wer_errors, total_words = calculate_wer(all_pred_word_seqs, all_true_word_seqs)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EVALUATION RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Phoneme Error Rate (PER): {per:.2f}%\")\n",
    "    print(f\"Word Error Rate (WER): {wer:.2f}%\")\n",
    "    print(f\"Total word errors: {wer_errors}\")\n",
    "    print(f\"Total words: {total_words}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Show samples\n",
    "    print(\"\\nSample Predictions (first 5):\")\n",
    "    for i in range(min(5, len(all_pred_phoneme_seqs))):\n",
    "        print(f\"\\n--- Sample {i+1} ---\")\n",
    "        \n",
    "        pred_phon_str = ' '.join([idx_to_phoneme[idx] for idx in all_pred_phoneme_seqs[i][:30]])\n",
    "        true_phon_str = ' '.join([idx_to_phoneme[idx] for idx in all_true_phoneme_seqs[i][:30]])\n",
    "        \n",
    "        print(f\"Pred Phonemes: {pred_phon_str}\")\n",
    "        print(f\"True Phonemes: {true_phon_str}\")\n",
    "        print(f\"Pred Words: {' '.join(all_pred_word_seqs[i])}\")\n",
    "        print(f\"True Words: {' '.join(all_true_word_seqs[i])}\")\n",
    "    \n",
    "    return {\n",
    "        'per': per,\n",
    "        'wer': wer,\n",
    "        'wer_errors': wer_errors,\n",
    "        'total_words': total_words,\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BRAIN-TO-TEXT WER EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Load validation data\n",
    "print(\"\\nLoading validation data...\")\n",
    "val_files = get_all_hdf5_files(BASE_PATH, \"val\")\n",
    "val_trials = load_full_dataset_info(val_files)\n",
    "val_ds = Brain2TextDatasetFull(val_trials)\n",
    "val_dl = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE_VAL, shuffle=False,\n",
    "    collate_fn=ctc_collate, num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "\n",
    "# 2. Load trained model\n",
    "print(\"\\nLoading trained model...\")\n",
    "model = BrainTransformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    d_model=D_MODEL,\n",
    "    nhead=NHEAD,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "print(f\"✓ Model loaded from {MODEL_PATH}\")\n",
    "print(f\"✓ Model has {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "\n",
    "# 3. Run evaluation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "results = evaluate_wer(\n",
    "    model=model,\n",
    "    dataloader=val_dl,\n",
    "    idx_to_phoneme=idx_to_phoneme,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"PER: {results['per']:.2f}%\")\n",
    "print(f\"WER: {results['wer']:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67625ada",
   "metadata": {
    "papermill": {
     "duration": 0.035842,
     "end_time": "2025-11-29T14:45:42.237138",
     "exception": false,
     "start_time": "2025-11-29T14:45:42.201296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13056355,
     "sourceId": 106809,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 518877,
     "modelInstanceId": 503803,
     "sourceId": 665621,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7375.175322,
   "end_time": "2025-11-29T14:45:45.004598",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-29T12:42:49.829276",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
